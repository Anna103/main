{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS579: Lecture 13  \n",
    "\n",
    "**Demographic Inference II**\n",
    "\n",
    "*[Dr. Aron Culotta](http://cs.iit.edu/~culotta)*  \n",
    "*[Illinois Institute of Technology](http://iit.edu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification\n",
    "\n",
    "Let's build a classifier to predict whether a Twitter user is male/female.\n",
    "\n",
    "We'll collect \"labeled\" training data using Census name list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.) Collect Census names. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4014 female and 1146 male names\n",
      "male name sample: ['curt', 'kareem', 'jae', 'granville', 'mason']\n",
      "female name sample: ['tandra', 'anisa', 'wilhelmina', 'huong', 'lily']\n"
     ]
    }
   ],
   "source": [
    "# Fetch male/female names from Census.\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_census_names():\n",
    "    \"\"\" Fetch a list of common male/female names from the census.\n",
    "    For ambiguous names, we select the more frequent gender.\"\"\"\n",
    "    males = requests.get('http://www2.census.gov/topics/genealogy/1990surnames/dist.male.first').text.split('\\n')\n",
    "    females = requests.get('http://www2.census.gov/topics/genealogy/1990surnames/dist.female.first').text.split('\\n')\n",
    "    males_pct = dict([(m.split()[0].lower(), float(m.split()[1]))\n",
    "                  for m in males if m])\n",
    "    females_pct = dict([(f.split()[0].lower(), float(f.split()[1]))\n",
    "                    for f in females if f])\n",
    "    male_names = set([m for m in males_pct if m not in females_pct or\n",
    "                  males_pct[m] > females_pct[m]])\n",
    "    female_names = set([f for f in females_pct if f not in males_pct or\n",
    "                  females_pct[f] > males_pct[f]])    \n",
    "    return male_names, female_names\n",
    "\n",
    "male_names, female_names = get_census_names()\n",
    "print('found %d female and %d male names' % (len(female_names), len(male_names)))\n",
    "print('male name sample:', list(male_names)[:5])\n",
    "print('female name sample:', list(female_names)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.) Sample 5K tweets with names on the Census list. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct TwitterAPI object.\n",
    "\n",
    "import configparser\n",
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "def get_twitter(config_file):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    twitter = TwitterAPI(\n",
    "                   config.get('twitter', 'consumer_key'),\n",
    "                   config.get('twitter', 'consumer_secret'),\n",
    "                   config.get('twitter', 'access_token'),\n",
    "                   config.get('twitter', 'access_token_secret'))\n",
    "    return twitter\n",
    "\n",
    "twitter = get_twitter('twitter.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample U.S. tweets with names from Census. \n",
    "import sys\n",
    "\n",
    "def get_first_name(tweet):\n",
    "    if 'user' in tweet and 'name' in tweet['user']:\n",
    "        parts = tweet['user']['name'].split()\n",
    "        if len(parts) > 0:\n",
    "            return parts[0].lower()\n",
    "\n",
    "def sample_tweets(twitter, limit, male_names, female_names):\n",
    "    tweets = []\n",
    "    while True:\n",
    "        try:\n",
    "            # Restrict to U.S.\n",
    "            for response in twitter.request('statuses/filter',\n",
    "                        {'locations':'-124.637,24.548,-66.993,48.9974'}):\n",
    "                if 'user' in response:\n",
    "                    name = get_first_name(response)\n",
    "                    if name in male_names or name in female_names:\n",
    "                        tweets.append(response)\n",
    "                        if len(tweets) % 100 == 0:\n",
    "                            print('found %d tweets' % len(tweets))\n",
    "                        if len(tweets) >= limit:\n",
    "                            return tweets\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100 tweets\n",
      "found 200 tweets\n",
      "found 300 tweets\n",
      "found 400 tweets\n",
      "found 500 tweets\n",
      "found 600 tweets\n",
      "found 700 tweets\n",
      "found 800 tweets\n",
      "found 900 tweets\n",
      "found 1000 tweets\n",
      "found 1100 tweets\n",
      "found 1200 tweets\n",
      "found 1300 tweets\n",
      "found 1400 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:<class 'urllib3.exceptions.ReadTimeoutError'> HTTPSConnectionPool(host='stream.twitter.com', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: <class 'TwitterAPI.TwitterError.TwitterConnectionError'>\n",
      "found 1500 tweets\n",
      "found 1600 tweets\n",
      "found 1700 tweets\n",
      "found 1800 tweets\n",
      "found 1900 tweets\n",
      "found 2000 tweets\n",
      "found 2100 tweets\n",
      "found 2200 tweets\n",
      "found 2300 tweets\n",
      "found 2400 tweets\n",
      "found 2500 tweets\n",
      "found 2600 tweets\n",
      "found 2700 tweets\n",
      "found 2800 tweets\n",
      "found 2900 tweets\n",
      "found 3000 tweets\n",
      "found 3100 tweets\n",
      "found 3200 tweets\n",
      "found 3300 tweets\n",
      "found 3400 tweets\n",
      "found 3500 tweets\n",
      "found 3600 tweets\n",
      "found 3700 tweets\n",
      "found 3800 tweets\n",
      "found 3900 tweets\n",
      "found 4000 tweets\n",
      "found 4100 tweets\n",
      "found 4200 tweets\n",
      "found 4300 tweets\n",
      "found 4400 tweets\n",
      "found 4500 tweets\n",
      "found 4600 tweets\n",
      "found 4700 tweets\n",
      "found 4800 tweets\n",
      "found 4900 tweets\n",
      "found 5000 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = sample_tweets(twitter, 5000, male_names, female_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-afd42103acbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# optionally read from disk or save to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweets.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets.pkl'"
     ]
    }
   ],
   "source": [
    "# optionally read from disk or save to disk\n",
    "#import pickle\n",
    "#tweets = pickle.load(open('tweets.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled 5000 tweets\n",
      "top names: [('david', 64), ('john', 63), ('michael', 61), ('chris', 52), ('kevin', 41), ('mike', 41), ('matt', 36), ('mark', 33), ('steve', 33), ('brian', 32), ('andrew', 28), ('kyle', 28), ('ryan', 27), ('scott', 27), ('joe', 27), ('jason', 26), ('jim', 26), ('william', 26), ('alex', 26), ('steven', 26), ('jay', 25), ('terry', 24), ('james', 24), ('rob', 23), ('dave', 23), ('michelle', 23), ('tom', 22), ('sean', 22), ('josh', 22), ('nick', 22)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('sampled %d tweets' % len(tweets))\n",
    "print('top names:', Counter(get_first_name(t) for t in tweets).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146 4014\n"
     ]
    }
   ],
   "source": [
    "print(len(male_names), len(female_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these tweets.\n",
    "import pickle\n",
    "pickle.dump(tweets, open('tweets.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.) Tokenize tweets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test tweet:\n",
      "\tscreen_name=shesbratty\n",
      "\tname=Christina Cox\n",
      "\tdescr=Emergency Medical Technician EMT, I’m a true Clemson Tiger Fan!! I’m a Wedding/Event Planner\n",
      "\ttext=Because I’m a first responder who doesn’t get paid a lot to save people’s lives\n"
     ]
    }
   ],
   "source": [
    "test_tweet = tweets[3]\n",
    "print('test tweet:\\n\\tscreen_name=%s\\n\\tname=%s\\n\\tdescr=%s\\n\\ttext=%s' %\n",
    "      (test_tweet['user']['screen_name'],\n",
    "       test_tweet['user']['name'],\n",
    "       test_tweet['user']['description'],\n",
    "       test_tweet['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(string, lowercase, keep_punctuation, prefix,\n",
    "             collapse_urls, collapse_mentions):\n",
    "    \"\"\" Split a tweet into tokens.\"\"\"\n",
    "    if not string:\n",
    "        return []\n",
    "    if lowercase:\n",
    "        string = string.lower()\n",
    "    tokens = []\n",
    "    if collapse_urls:\n",
    "        string = re.sub('http\\S+', 'THIS_IS_A_URL', string)\n",
    "    if collapse_mentions:\n",
    "        string = re.sub('@\\S+', 'THIS_IS_A_MENTION', string)\n",
    "    if keep_punctuation:\n",
    "        tokens = string.split()\n",
    "    else:\n",
    "        tokens = re.sub('\\W+', ' ', string).split()\n",
    "    if prefix:\n",
    "        tokens = ['%s%s' % (prefix, t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d=emergency',\n",
       " 'd=medical',\n",
       " 'd=technician',\n",
       " 'd=emt',\n",
       " 'd=i',\n",
       " 'd=m',\n",
       " 'd=a',\n",
       " 'd=true',\n",
       " 'd=clemson',\n",
       " 'd=tiger',\n",
       " 'd=fan',\n",
       " 'd=i',\n",
       " 'd=m',\n",
       " 'd=a',\n",
       " 'd=wedding',\n",
       " 'd=event',\n",
       " 'd=planner']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(test_tweet['user']['description'], lowercase=True,\n",
    "         keep_punctuation=False, prefix='d=',\n",
    "         collapse_urls=True, collapse_mentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d=apple', 'd=banana', 'd=went', 'd=to', 'd=the', 'd=store']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('apple-banana went to the store!', lowercase=True,\n",
    "         keep_punctuation=False, prefix='d=',\n",
    "         collapse_urls=True, collapse_mentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t=because',\n",
       " 't=i’m',\n",
       " 't=a',\n",
       " 't=first',\n",
       " 't=responder',\n",
       " 't=who',\n",
       " 't=doesn’t',\n",
       " 't=get',\n",
       " 't=paid',\n",
       " 't=a',\n",
       " 't=lot',\n",
       " 't=to',\n",
       " 't=save',\n",
       " 't=people’s',\n",
       " 't=lives']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(test_tweet['text'], lowercase=True, keep_punctuation=True,\n",
    "         prefix='t=',\n",
    "         collapse_urls=True, collapse_mentions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet2tokens(tweet, use_descr=True, lowercase=True,\n",
    "                 keep_punctuation=True, descr_prefix='d=',\n",
    "                 collapse_urls=True, collapse_mentions=True):\n",
    "    \"\"\" Convert a tweet into a list of tokens, from the tweet text and optionally the\n",
    "    user description. \"\"\"\n",
    "    tokens = tokenize(tweet['text'], lowercase, keep_punctuation, None,\n",
    "                       collapse_urls, collapse_mentions)\n",
    "    if use_descr:\n",
    "        tokens.extend(tokenize(tweet['user']['description'], lowercase,\n",
    "                               keep_punctuation, descr_prefix,\n",
    "                               collapse_urls, collapse_mentions))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['because',\n",
       " 'i’m',\n",
       " 'a',\n",
       " 'first',\n",
       " 'responder',\n",
       " 'who',\n",
       " 'doesn’t',\n",
       " 'get',\n",
       " 'paid',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'save',\n",
       " 'people’s',\n",
       " 'lives',\n",
       " 'd=emergency',\n",
       " 'd=medical',\n",
       " 'd=technician',\n",
       " 'd=emt,',\n",
       " 'd=i’m',\n",
       " 'd=a',\n",
       " 'd=true',\n",
       " 'd=clemson',\n",
       " 'd=tiger',\n",
       " 'd=fan!!',\n",
       " 'd=i’m',\n",
       " 'd=a',\n",
       " 'd=wedding/event',\n",
       " 'd=planner']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet2tokens(test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=emergency  d=medical  d=technician  d=emt,  d=i’m  d=a  d=true  d=clemson  d=tiger  d=fan!!  d=i’m  d=a  d=wedding/event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=emergency  d=medical  d=technician  d=emt,  d=i’m  d=a  d=true  d=clemson  d=tiger  d=fan!!  d=i’m  d=a  d=wedding/event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=emergency  d=medical  d=technician  d=emt,  d=i’m  d=a  d=true  d=clemson  d=tiger  d=fan!!  d=i’m  d=a  d=wedding/event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=emergency  d=medical  d=technician  d=emt,  d=i’m  d=a  d=true  d=clemson  d=tiger  d=fan!!  d=i’m  d=a  d=wedding/event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  emergency  medical  technician  emt,  i’m  a  true  clemson  tiger  fan!!  i’m  a  wedding/event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  emergency  medical  technician  emt,  i’m  a  true  clemson  tiger  fan!!  i’m  a  wedding/event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  emergency  medical  technician  emt,  i’m  a  true  clemson  tiger  fan!!  i’m  a  wedding/event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  emergency  medical  technician  emt,  i’m  a  true  clemson  tiger  fan!!  i’m  a  wedding/event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=emergency  d=medical  d=technician  d=emt  d=i  d=m  d=a  d=true  d=clemson  d=tiger  d=fan  d=i  d=m  d=a  d=wedding  d=event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=emergency  d=medical  d=technician  d=emt  d=i  d=m  d=a  d=true  d=clemson  d=tiger  d=fan  d=i  d=m  d=a  d=wedding  d=event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=emergency  d=medical  d=technician  d=emt  d=i  d=m  d=a  d=true  d=clemson  d=tiger  d=fan  d=i  d=m  d=a  d=wedding  d=event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=emergency  d=medical  d=technician  d=emt  d=i  d=m  d=a  d=true  d=clemson  d=tiger  d=fan  d=i  d=m  d=a  d=wedding  d=event  d=planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  emergency  medical  technician  emt  i  m  a  true  clemson  tiger  fan  i  m  a  wedding  event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  emergency  medical  technician  emt  i  m  a  true  clemson  tiger  fan  i  m  a  wedding  event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  emergency  medical  technician  emt  i  m  a  true  clemson  tiger  fan  i  m  a  wedding  event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  emergency  medical  technician  emt  i  m  a  true  clemson  tiger  fan  i  m  a  wedding  event  planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=Emergency  d=Medical  d=Technician  d=EMT,  d=I’m  d=a  d=true  d=Clemson  d=Tiger  d=Fan!!  d=I’m  d=a  d=Wedding/Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=Emergency  d=Medical  d=Technician  d=EMT,  d=I’m  d=a  d=true  d=Clemson  d=Tiger  d=Fan!!  d=I’m  d=a  d=Wedding/Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=Emergency  d=Medical  d=Technician  d=EMT,  d=I’m  d=a  d=true  d=Clemson  d=Tiger  d=Fan!!  d=I’m  d=a  d=Wedding/Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  d=Emergency  d=Medical  d=Technician  d=EMT,  d=I’m  d=a  d=true  d=Clemson  d=Tiger  d=Fan!!  d=I’m  d=a  d=Wedding/Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  Emergency  Medical  Technician  EMT,  I’m  a  true  Clemson  Tiger  Fan!!  I’m  a  Wedding/Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  Emergency  Medical  Technician  EMT,  I’m  a  true  Clemson  Tiger  Fan!!  I’m  a  Wedding/Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  Emergency  Medical  Technician  EMT,  I’m  a  true  Clemson  Tiger  Fan!!  I’m  a  Wedding/Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives  Emergency  Medical  Technician  EMT,  I’m  a  true  Clemson  Tiger  Fan!!  I’m  a  Wedding/Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=Emergency  d=Medical  d=Technician  d=EMT  d=I  d=m  d=a  d=true  d=Clemson  d=Tiger  d=Fan  d=I  d=m  d=a  d=Wedding  d=Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=Emergency  d=Medical  d=Technician  d=EMT  d=I  d=m  d=a  d=true  d=Clemson  d=Tiger  d=Fan  d=I  d=m  d=a  d=Wedding  d=Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=Emergency  d=Medical  d=Technician  d=EMT  d=I  d=m  d=a  d=true  d=Clemson  d=Tiger  d=Fan  d=I  d=m  d=a  d=Wedding  d=Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  d=Emergency  d=Medical  d=Technician  d=EMT  d=I  d=m  d=a  d=true  d=Clemson  d=Tiger  d=Fan  d=I  d=m  d=a  d=Wedding  d=Event  d=Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  Emergency  Medical  Technician  EMT  I  m  a  true  Clemson  Tiger  Fan  I  m  a  Wedding  Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  Emergency  Medical  Technician  EMT  I  m  a  true  Clemson  Tiger  Fan  I  m  a  Wedding  Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  Emergency  Medical  Technician  EMT  I  m  a  true  Clemson  Tiger  Fan  I  m  a  Wedding  Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives  Emergency  Medical  Technician  EMT  I  m  a  true  Clemson  Tiger  Fan  I  m  a  Wedding  Event  Planner \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "because  i’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "because  i  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "Because  I’m  a  first  responder  who  doesn’t  get  paid  a  lot  to  save  people’s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "Because  I  m  a  first  responder  who  doesn  t  get  paid  a  lot  to  save  people  s  lives \n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for enumerating all possible arguments of tweet2tokens\n",
    "# https://docs.python.org/2/library/itertools.html#itertools.product\n",
    "from itertools import product\n",
    "\n",
    "use_descr_opts = [True, False]\n",
    "lowercase_opts = [True, False]\n",
    "keep_punctuation_opts = [True, False]\n",
    "descr_prefix_opts = ['d=', '']\n",
    "url_opts = [True, False]\n",
    "mention_opts = [True, False]\n",
    "\n",
    "argnames = ['use_descr', 'lower', 'punct', 'prefix', 'url', 'mention']\n",
    "option_iter = product(use_descr_opts, lowercase_opts,\n",
    "                       keep_punctuation_opts,\n",
    "                       descr_prefix_opts, url_opts,\n",
    "                       mention_opts)\n",
    "for options in option_iter:\n",
    "    print('  '.join('%s=%s' % (name, opt) \n",
    "                    for name, opt in zip(argnames, options)))\n",
    "    print\n",
    "    print('  '.join(tweet2tokens(test_tweet, *options)), '\\n----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tokenize all tweets.\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=False, descr_prefix='d=',\n",
    "                            collapse_urls=True, collapse_mentions=True)\n",
    "              for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['its',\n",
       " 'ohdee',\n",
       " 'hot',\n",
       " 'd=inquires',\n",
       " 'd=prodbyjah24THIS_IS_A_MENTION',\n",
       " 'd=muterkelly']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(lambda: [])\n",
    "d['cat'].append(10)\n",
    "d['cat']\n",
    "#v = {}\n",
    "#v['cat'].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store these in a sparse matrix.\n",
    "\n",
    "#1) Create a vocabulary (dict from term->index)\n",
    "\n",
    "# https://docs.python.org/2/library/collections.html#collections.defaultdict\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_vocabulary(tokens_list):\n",
    "    vocabulary = defaultdict(lambda: len(vocabulary))  # If term not present, assign next int.\n",
    "    for tokens in tokens_list:\n",
    "        for token in tokens:\n",
    "            vocabulary[token]  # looking up a key; defaultdict takes care of assigning it a value.\n",
    "    print('%d unique terms in vocabulary' % len(vocabulary))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20814 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('power', 0),\n",
       " ('peaker', 1),\n",
       " ('m1w1d3', 2),\n",
       " ('only', 3),\n",
       " ('1', 4),\n",
       " ('page', 5),\n",
       " ('today', 6),\n",
       " ('but', 7),\n",
       " ('took', 8),\n",
       " ('nearly', 9)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term->index\n",
    "list(vocabulary.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30255 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# How big is vocabulary if we keep punctuation?\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=True, descr_prefix='d=',\n",
    "                            collapse_urls=True, collapse_mentions=True)\n",
    "              for t in tweets]\n",
    "\n",
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32357 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# How big is vocabulary if we keep punctuation and urls?\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=True, descr_prefix='d=',\n",
    "                            collapse_urls=False, collapse_mentions=True)\n",
    "              for t in tweets]\n",
    "\n",
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36980 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# How big is vocabulary if we keep punctuation and urls and mentions?\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=True, descr_prefix='d=',\n",
    "                            collapse_urls=False, collapse_mentions=False)\n",
    "              for t in tweets]\n",
    "\n",
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vector Matrix\n",
    "\n",
    "Create a matrix $X$ where $X[i,j]$ is the frequency of term $j$ in tweet $i$.\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{tweet}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{tweet}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrices\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{tweet}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{tweet}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$X$ is mostly $0$ for text problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of List (LIL) Matrix\n",
    "\n",
    "Store a linked list of (index, value) pairs for each row.\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "\\hbox{tweet}_1 & (0, 1)\\\\\n",
    "\\hbox{tweet}_2 & (3,2)\\\\\n",
    "\\hbox{tweet}_3 & (0,1), (1,1)\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Advantage:** Fast to construct: append to list in constant time.\n",
    "\n",
    "**Disadvantage:** Slow random access for matrix-vector product.\n",
    "\n",
    "E.g., $\\hat{z} = X\\cdot \\hat{\\beta}$ to classify tweets using a learned weight vector $\\beta$\n",
    "\n",
    "$\\hat{z}[i] = \\sum_j X[i,j] * \\beta[j]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed Sparse Row (CSR) Matrix\n",
    "\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{tweet}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{tweet}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_4 & 1  &  0  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "CSR Matrix is an object with three attributes: \n",
    "- **val:** $\\{1,2,1,1,1\\}$  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *list of all non-zero values*  \n",
    "- **col_ind:** $\\{0,3,0,1,0\\}$ &nbsp; *column index for each non-zero value* (e.g., first non-zero value (1) is in column 0) \n",
    "- **row_ptr:** $\\{0,1,2,4\\}$ &nbsp;&nbsp;&nbsp; *index into **col_ind** where each row starts* (e.g., tweet3, term1 corresponds to col_ind[2])\n",
    "\n",
    "Allows efficient row access (good for us, since each row is a tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to a sparse matrix X.\n",
    "# X[i,j] is the frequency of term j in tweet i\n",
    "# \n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def make_feature_matrix(tokens_list, vocabulary):\n",
    "    X = lil_matrix((len(tweets), len(vocabulary)))\n",
    "    for i, tokens in enumerate(tokens_list):\n",
    "        for token in tokens:\n",
    "            j = vocabulary[token]\n",
    "            X[i,j] += 1\n",
    "    return X.tocsr()  # convert to CSR for more efficient random access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (5000, 36980)\n"
     ]
    }
   ],
   "source": [
    "X = make_feature_matrix(tokens_list, vocabulary)\n",
    "print('shape of X:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on csr_matrix in module scipy.sparse.csr object:\n",
      "\n",
      "class csr_matrix(scipy.sparse.compressed._cs_matrix, scipy.sparse.sputils.IndexMixin)\n",
      " |  csr_matrix(arg1, shape=None, dtype=None, copy=False)\n",
      " |  \n",
      " |  Compressed Sparse Row matrix\n",
      " |  \n",
      " |  This can be instantiated in several ways:\n",
      " |      csr_matrix(D)\n",
      " |          with a dense matrix or rank-2 ndarray D\n",
      " |  \n",
      " |      csr_matrix(S)\n",
      " |          with another sparse matrix S (equivalent to S.tocsr())\n",
      " |  \n",
      " |      csr_matrix((M, N), [dtype])\n",
      " |          to construct an empty matrix with shape (M, N)\n",
      " |          dtype is optional, defaulting to dtype='d'.\n",
      " |  \n",
      " |      csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
      " |          where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
      " |          relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
      " |  \n",
      " |      csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
      " |          is the standard CSR representation where the column indices for\n",
      " |          row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
      " |          corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
      " |          If the shape parameter is not supplied, the matrix dimensions\n",
      " |          are inferred from the index arrays.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  dtype : dtype\n",
      " |      Data type of the matrix\n",
      " |  shape : 2-tuple\n",
      " |      Shape of the matrix\n",
      " |  ndim : int\n",
      " |      Number of dimensions (this is always 2)\n",
      " |  nnz\n",
      " |      Number of nonzero elements\n",
      " |  data\n",
      " |      CSR format data array of the matrix\n",
      " |  indices\n",
      " |      CSR format index array of the matrix\n",
      " |  indptr\n",
      " |      CSR format index pointer array of the matrix\n",
      " |  has_sorted_indices\n",
      " |      Whether indices are sorted\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  \n",
      " |  Sparse matrices can be used in arithmetic operations: they support\n",
      " |  addition, subtraction, multiplication, division, and matrix power.\n",
      " |  \n",
      " |  Advantages of the CSR format\n",
      " |    - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
      " |    - efficient row slicing\n",
      " |    - fast matrix vector products\n",
      " |  \n",
      " |  Disadvantages of the CSR format\n",
      " |    - slow column slicing operations (consider CSC)\n",
      " |    - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from scipy.sparse import csr_matrix\n",
      " |  >>> csr_matrix((3, 4), dtype=np.int8).toarray()\n",
      " |  array([[0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0]], dtype=int8)\n",
      " |  \n",
      " |  >>> row = np.array([0, 0, 1, 2, 2, 2])\n",
      " |  >>> col = np.array([0, 2, 2, 0, 1, 2])\n",
      " |  >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
      " |  array([[1, 0, 2],\n",
      " |         [0, 0, 3],\n",
      " |         [4, 5, 6]])\n",
      " |  \n",
      " |  >>> indptr = np.array([0, 2, 3, 6])\n",
      " |  >>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
      " |  >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
      " |  array([[1, 0, 2],\n",
      " |         [0, 0, 3],\n",
      " |         [4, 5, 6]])\n",
      " |  \n",
      " |  As an example of how to construct a CSR matrix incrementally,\n",
      " |  the following snippet builds a term-document matrix from texts:\n",
      " |  \n",
      " |  >>> docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
      " |  >>> indptr = [0]\n",
      " |  >>> indices = []\n",
      " |  >>> data = []\n",
      " |  >>> vocabulary = {}\n",
      " |  >>> for d in docs:\n",
      " |  ...     for term in d:\n",
      " |  ...         index = vocabulary.setdefault(term, len(vocabulary))\n",
      " |  ...         indices.append(index)\n",
      " |  ...         data.append(1)\n",
      " |  ...     indptr.append(len(indices))\n",
      " |  ...\n",
      " |  >>> csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
      " |  array([[2, 1, 0, 0],\n",
      " |         [0, 1, 1, 1]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      csr_matrix\n",
      " |      scipy.sparse.compressed._cs_matrix\n",
      " |      scipy.sparse.data._data_matrix\n",
      " |      scipy.sparse.base.spmatrix\n",
      " |      scipy.sparse.data._minmax_mixin\n",
      " |      scipy.sparse.sputils.IndexMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  getcol(self, i)\n",
      " |      Returns a copy of column i of the matrix, as a (m x 1)\n",
      " |      CSR matrix (column vector).\n",
      " |  \n",
      " |  getrow(self, i)\n",
      " |      Returns a copy of row i of the matrix, as a (1 x n)\n",
      " |      CSR matrix (row vector).\n",
      " |  \n",
      " |  tobsr(self, blocksize=None, copy=True)\n",
      " |      Convert this matrix to Block Sparse Row format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant bsr_matrix.\n",
      " |      \n",
      " |      When blocksize=(R, C) is provided, it will be used for construction of\n",
      " |      the bsr_matrix.\n",
      " |  \n",
      " |  tocsc(self, copy=False)\n",
      " |      Convert this matrix to Compressed Sparse Column format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant csc_matrix.\n",
      " |  \n",
      " |  tocsr(self, copy=False)\n",
      " |      Convert this matrix to Compressed Sparse Row format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant csr_matrix.\n",
      " |  \n",
      " |  tolil(self, copy=False)\n",
      " |      Convert this matrix to LInked List format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant lil_matrix.\n",
      " |  \n",
      " |  transpose(self, axes=None, copy=False)\n",
      " |      Reverses the dimensions of the sparse matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axes : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except\n",
      " |          for the default value.\n",
      " |      copy : bool, optional\n",
      " |          Indicates whether or not attributes of `self` should be\n",
      " |          copied whenever possible. The degree to which attributes\n",
      " |          are copied varies depending on the type of sparse matrix\n",
      " |          being used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : `self` with the dimensions reversed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      np.matrix.transpose : NumPy's implementation of 'transpose'\n",
      " |                            for matrices\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  format = 'csr'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, arg1, shape=None, dtype=None, copy=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __setitem__(self, index, x)\n",
      " |  \n",
      " |  check_format(self, full_check=True)\n",
      " |      check whether the matrix format is valid\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      full_check : bool, optional\n",
      " |          If `True`, rigorous check, O(N) operations. Otherwise\n",
      " |          basic check, O(1) operations (default True).\n",
      " |  \n",
      " |  diagonal(self, k=0)\n",
      " |      Returns the k-th diagonal of the matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      k : int, optional\n",
      " |          Which diagonal to set, corresponding to elements a[i, i+k].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.diagonal : Equivalent numpy function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
      " |      >>> A.diagonal()\n",
      " |      array([1, 0, 5])\n",
      " |      >>> A.diagonal(k=1)\n",
      " |      array([2, 3])\n",
      " |  \n",
      " |  eliminate_zeros(self)\n",
      " |      Remove zero entries from the matrix\n",
      " |      \n",
      " |      This is an *in place* operation\n",
      " |  \n",
      " |  getnnz(self, axis=None)\n",
      " |      Number of stored values, including explicit zeros.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, 0, or 1\n",
      " |          Select between the number of values across the whole matrix, in\n",
      " |          each column, or in each row.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      count_nonzero : Number of non-zero entries\n",
      " |  \n",
      " |  maximum(self, other)\n",
      " |      Element-wise maximum between this and another matrix.\n",
      " |  \n",
      " |  minimum(self, other)\n",
      " |      Element-wise minimum between this and another matrix.\n",
      " |  \n",
      " |  multiply(self, other)\n",
      " |      Point-wise multiplication by another matrix, vector, or\n",
      " |      scalar.\n",
      " |  \n",
      " |  prune(self)\n",
      " |      Remove empty space after all non-zero elements.\n",
      " |  \n",
      " |  resize(self, *shape)\n",
      " |      Resize the matrix in-place to dimensions given by ``shape``\n",
      " |      \n",
      " |      Any elements that lie within the new shape will remain at the same\n",
      " |      indices, while non-zero elements lying outside the new shape are\n",
      " |      removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shape : (int, int)\n",
      " |          number of rows and columns in the new matrix\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The semantics are not identical to `numpy.ndarray.resize` or\n",
      " |      `numpy.resize`.  Here, the same data will be maintained at each index\n",
      " |      before and after reshape, if that index is within the new bounds.  In\n",
      " |      numpy, resizing maintains contiguity of the array, moving elements\n",
      " |      around in the logical matrix but not within a flattened representation.\n",
      " |      \n",
      " |      We give no guarantees about whether the underlying data attributes\n",
      " |      (arrays, etc.) will be modified in place or replaced with new objects.\n",
      " |  \n",
      " |  sort_indices(self)\n",
      " |      Sort the indices of this matrix *in place*\n",
      " |  \n",
      " |  sorted_indices(self)\n",
      " |      Return a copy of this matrix with sorted indices\n",
      " |  \n",
      " |  sum(self, axis=None, dtype=None, out=None)\n",
      " |      Sum the matrix elements over a given axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the sum is computed. The default is to\n",
      " |          compute the sum of all the matrix elements, returning a scalar\n",
      " |          (i.e. `axis` = `None`).\n",
      " |      dtype : dtype, optional\n",
      " |          The type of the returned matrix and of the accumulator in which\n",
      " |          the elements are summed.  The dtype of `a` is used by default\n",
      " |          unless `a` has an integer dtype of less precision than the default\n",
      " |          platform integer.  In that case, if `a` is signed then the platform\n",
      " |          integer is used while if `a` is unsigned then an unsigned integer\n",
      " |          of the same precision as the platform integer is used.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      out : np.matrix, optional\n",
      " |          Alternative output matrix in which to place the result. It must\n",
      " |          have the same shape as the expected output, but the type of the\n",
      " |          output values will be cast if necessary.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum_along_axis : np.matrix\n",
      " |          A matrix with the same shape as `self`, with the specified\n",
      " |          axis removed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      np.matrix.sum : NumPy's implementation of 'sum' for matrices\n",
      " |  \n",
      " |  sum_duplicates(self)\n",
      " |      Eliminate duplicate matrix entries by adding them together\n",
      " |      \n",
      " |      The is an *in place* operation\n",
      " |  \n",
      " |  toarray(self, order=None, out=None)\n",
      " |      Return a dense ndarray representation of this matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Whether to store multi-dimensional data in C (row-major)\n",
      " |          or Fortran (column-major) order in memory. The default\n",
      " |          is 'None', indicating the NumPy default of C-ordered.\n",
      " |          Cannot be specified in conjunction with the `out`\n",
      " |          argument.\n",
      " |      \n",
      " |      out : ndarray, 2-dimensional, optional\n",
      " |          If specified, uses this array as the output buffer\n",
      " |          instead of allocating a new array to return. The provided\n",
      " |          array must have the same shape and dtype as the sparse\n",
      " |          matrix on which you are calling the method. For most\n",
      " |          sparse types, `out` is required to be memory contiguous\n",
      " |          (either C or Fortran ordered).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : ndarray, 2-dimensional\n",
      " |          An array with the same shape and containing the same\n",
      " |          data represented by the sparse matrix, with the requested\n",
      " |          memory order. If `out` was passed, the same object is\n",
      " |          returned after being modified in-place to contain the\n",
      " |          appropriate values.\n",
      " |  \n",
      " |  tocoo(self, copy=True)\n",
      " |      Convert this matrix to COOrdinate format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant coo_matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  has_canonical_format\n",
      " |      Determine whether the matrix has sorted indices and no duplicates\n",
      " |      \n",
      " |      Returns\n",
      " |          - True: if the above applies\n",
      " |          - False: otherwise\n",
      " |      \n",
      " |      has_canonical_format implies has_sorted_indices, so if the latter flag\n",
      " |      is False, so will the former be; if the former is found True, the\n",
      " |      latter flag is also set.\n",
      " |  \n",
      " |  has_sorted_indices\n",
      " |      Determine whether the matrix has sorted indices\n",
      " |      \n",
      " |      Returns\n",
      " |          - True: if the indices of the matrix are in sorted order\n",
      " |          - False: otherwise\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.data._data_matrix:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  arcsin(self)\n",
      " |      Element-wise arcsin.\n",
      " |      \n",
      " |      See numpy.arcsin for more information.\n",
      " |  \n",
      " |  arcsinh(self)\n",
      " |      Element-wise arcsinh.\n",
      " |      \n",
      " |      See numpy.arcsinh for more information.\n",
      " |  \n",
      " |  arctan(self)\n",
      " |      Element-wise arctan.\n",
      " |      \n",
      " |      See numpy.arctan for more information.\n",
      " |  \n",
      " |  arctanh(self)\n",
      " |      Element-wise arctanh.\n",
      " |      \n",
      " |      See numpy.arctanh for more information.\n",
      " |  \n",
      " |  astype(self, dtype, casting='unsafe', copy=True)\n",
      " |      Cast the matrix elements to a specified type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : string or numpy dtype\n",
      " |          Typecode or data-type to which to cast the data.\n",
      " |      casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      " |          Controls what kind of data casting may occur.\n",
      " |          Defaults to 'unsafe' for backwards compatibility.\n",
      " |          'no' means the data types should not be cast at all.\n",
      " |          'equiv' means only byte-order changes are allowed.\n",
      " |          'safe' means only casts which can preserve values are allowed.\n",
      " |          'same_kind' means only safe casts or casts within a kind,\n",
      " |          like float64 to float32, are allowed.\n",
      " |          'unsafe' means any data conversions may be done.\n",
      " |      copy : bool, optional\n",
      " |          If `copy` is `False`, the result might share some memory with this\n",
      " |          matrix. If `copy` is `True`, it is guaranteed that the result and\n",
      " |          this matrix do not share any memory.\n",
      " |  \n",
      " |  ceil(self)\n",
      " |      Element-wise ceil.\n",
      " |      \n",
      " |      See numpy.ceil for more information.\n",
      " |  \n",
      " |  conj(self, copy=True)\n",
      " |      Element-wise complex conjugation.\n",
      " |      \n",
      " |      If the matrix is of non-complex data type and `copy` is False,\n",
      " |      this method does nothing and the data is not copied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, optional\n",
      " |          If True, the result is guaranteed to not share data with self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : The element-wise complex conjugate.\n",
      " |  \n",
      " |  copy(self)\n",
      " |      Returns a copy of this matrix.\n",
      " |      \n",
      " |      No data/indices will be shared between the returned value and current\n",
      " |      matrix.\n",
      " |  \n",
      " |  count_nonzero(self)\n",
      " |      Number of non-zero entries, equivalent to\n",
      " |      \n",
      " |      np.count_nonzero(a.toarray())\n",
      " |      \n",
      " |      Unlike getnnz() and the nnz property, which return the number of stored\n",
      " |      entries (the length of the data attribute), this method counts the\n",
      " |      actual number of non-zero entries in data.\n",
      " |  \n",
      " |  deg2rad(self)\n",
      " |      Element-wise deg2rad.\n",
      " |      \n",
      " |      See numpy.deg2rad for more information.\n",
      " |  \n",
      " |  expm1(self)\n",
      " |      Element-wise expm1.\n",
      " |      \n",
      " |      See numpy.expm1 for more information.\n",
      " |  \n",
      " |  floor(self)\n",
      " |      Element-wise floor.\n",
      " |      \n",
      " |      See numpy.floor for more information.\n",
      " |  \n",
      " |  log1p(self)\n",
      " |      Element-wise log1p.\n",
      " |      \n",
      " |      See numpy.log1p for more information.\n",
      " |  \n",
      " |  power(self, n, dtype=None)\n",
      " |      This function performs element-wise power.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : n is a scalar\n",
      " |      \n",
      " |      dtype : If dtype is not specified, the current dtype will be preserved.\n",
      " |  \n",
      " |  rad2deg(self)\n",
      " |      Element-wise rad2deg.\n",
      " |      \n",
      " |      See numpy.rad2deg for more information.\n",
      " |  \n",
      " |  rint(self)\n",
      " |      Element-wise rint.\n",
      " |      \n",
      " |      See numpy.rint for more information.\n",
      " |  \n",
      " |  sign(self)\n",
      " |      Element-wise sign.\n",
      " |      \n",
      " |      See numpy.sign for more information.\n",
      " |  \n",
      " |  sin(self)\n",
      " |      Element-wise sin.\n",
      " |      \n",
      " |      See numpy.sin for more information.\n",
      " |  \n",
      " |  sinh(self)\n",
      " |      Element-wise sinh.\n",
      " |      \n",
      " |      See numpy.sinh for more information.\n",
      " |  \n",
      " |  sqrt(self)\n",
      " |      Element-wise sqrt.\n",
      " |      \n",
      " |      See numpy.sqrt for more information.\n",
      " |  \n",
      " |  tan(self)\n",
      " |      Element-wise tan.\n",
      " |      \n",
      " |      See numpy.tan for more information.\n",
      " |  \n",
      " |  tanh(self)\n",
      " |      Element-wise tanh.\n",
      " |      \n",
      " |      See numpy.tanh for more information.\n",
      " |  \n",
      " |  trunc(self)\n",
      " |      Element-wise trunc.\n",
      " |      \n",
      " |      See numpy.trunc for more information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.data._data_matrix:\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __div__(self, other)\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __idiv__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      # What should len(sparse) return? For consistency with dense matrices,\n",
      " |      # perhaps it should be the number of rows?  But for some uses the number of\n",
      " |      # non-zeros is more important.  For now, raise an exception!\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |      interpret other and call one of the following\n",
      " |      \n",
      " |      self._mul_scalar()\n",
      " |      self._mul_vector()\n",
      " |      self._mul_multivector()\n",
      " |      self._mul_sparse_matrix()\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rdiv__(self, other)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  asformat(self, format, copy=False)\n",
      " |      Return this matrix in the passed sparse format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      format : {str, None}\n",
      " |          The desired sparse matrix format (\"csr\", \"csc\", \"lil\", \"dok\", ...)\n",
      " |          or None for no conversion.\n",
      " |      copy : bool, optional\n",
      " |          If True, the result is guaranteed to not share data with self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : This matrix in the passed sparse format.\n",
      " |  \n",
      " |  asfptype(self)\n",
      " |      Upcast matrix to a floating point format (if necessary)\n",
      " |  \n",
      " |  conjugate(self, copy=True)\n",
      " |      Element-wise complex conjugation.\n",
      " |      \n",
      " |      If the matrix is of non-complex data type and `copy` is False,\n",
      " |      this method does nothing and the data is not copied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, optional\n",
      " |          If True, the result is guaranteed to not share data with self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : The element-wise complex conjugate.\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Ordinary dot product\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
      " |      >>> v = np.array([1, 0, -1])\n",
      " |      >>> A.dot(v)\n",
      " |      array([ 1, -3, -1], dtype=int64)\n",
      " |  \n",
      " |  getH(self)\n",
      " |      Return the Hermitian transpose of this matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      np.matrix.getH : NumPy's implementation of `getH` for matrices\n",
      " |  \n",
      " |  get_shape(self)\n",
      " |      Get shape of a matrix.\n",
      " |  \n",
      " |  getformat(self)\n",
      " |      Format of a matrix representation as a string.\n",
      " |  \n",
      " |  getmaxprint(self)\n",
      " |      Maximum number of elements to display when printed.\n",
      " |  \n",
      " |  mean(self, axis=None, dtype=None, out=None)\n",
      " |      Compute the arithmetic mean along the specified axis.\n",
      " |      \n",
      " |      Returns the average of the matrix elements. The average is taken\n",
      " |      over all elements in the matrix by default, otherwise over the\n",
      " |      specified axis. `float64` intermediate and return values are used\n",
      " |      for integer inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the mean is computed. The default is to compute\n",
      " |          the mean of all elements in the matrix (i.e. `axis` = `None`).\n",
      " |      dtype : data-type, optional\n",
      " |          Type to use in computing the mean. For integer inputs, the default\n",
      " |          is `float64`; for floating point inputs, it is the same as the\n",
      " |          input dtype.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      out : np.matrix, optional\n",
      " |          Alternative output matrix in which to place the result. It must\n",
      " |          have the same shape as the expected output, but the type of the\n",
      " |          output values will be cast if necessary.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      m : np.matrix\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      np.matrix.mean : NumPy's implementation of 'mean' for matrices\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      nonzero indices\n",
      " |      \n",
      " |      Returns a tuple of arrays (row,col) containing the indices\n",
      " |      of the non-zero elements of the matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1,2,0],[0,0,3],[4,0,5]])\n",
      " |      >>> A.nonzero()\n",
      " |      (array([0, 0, 1, 2, 2]), array([0, 1, 2, 0, 2]))\n",
      " |  \n",
      " |  reshape(self, *args, **kwargs)\n",
      " |      reshape(self, shape, order='C', copy=False)\n",
      " |      \n",
      " |      Gives a new shape to a sparse matrix without changing its data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shape : length-2 tuple of ints\n",
      " |          The new shape should be compatible with the original shape.\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Read the elements using this index order. 'C' means to read and\n",
      " |          write the elements using C-like index order; e.g. read entire first\n",
      " |          row, then second row, etc. 'F' means to read and write the elements\n",
      " |          using Fortran-like index order; e.g. read entire first column, then\n",
      " |          second column, etc.\n",
      " |      copy : bool, optional\n",
      " |          Indicates whether or not attributes of self should be copied\n",
      " |          whenever possible. The degree to which attributes are copied varies\n",
      " |          depending on the type of sparse matrix being used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reshaped_matrix : sparse matrix\n",
      " |          A sparse matrix with the given `shape`, not necessarily of the same\n",
      " |          format as the current object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      np.matrix.reshape : NumPy's implementation of 'reshape' for matrices\n",
      " |  \n",
      " |  set_shape(self, shape)\n",
      " |      See `reshape`.\n",
      " |  \n",
      " |  setdiag(self, values, k=0)\n",
      " |      Set diagonal or off-diagonal elements of the array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : array_like\n",
      " |          New values of the diagonal elements.\n",
      " |      \n",
      " |          Values may have any length.  If the diagonal is longer than values,\n",
      " |          then the remaining diagonal entries will not be set.  If values if\n",
      " |          longer than the diagonal, then the remaining values are ignored.\n",
      " |      \n",
      " |          If a scalar value is given, all of the diagonal is set to it.\n",
      " |      \n",
      " |      k : int, optional\n",
      " |          Which off-diagonal to set, corresponding to elements a[i,i+k].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |  \n",
      " |  todense(self, order=None, out=None)\n",
      " |      Return a dense matrix representation of this matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Whether to store multi-dimensional data in C (row-major)\n",
      " |          or Fortran (column-major) order in memory. The default\n",
      " |          is 'None', indicating the NumPy default of C-ordered.\n",
      " |          Cannot be specified in conjunction with the `out`\n",
      " |          argument.\n",
      " |      \n",
      " |      out : ndarray, 2-dimensional, optional\n",
      " |          If specified, uses this array (or `numpy.matrix`) as the\n",
      " |          output buffer instead of allocating a new array to\n",
      " |          return. The provided array must have the same shape and\n",
      " |          dtype as the sparse matrix on which you are calling the\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.matrix, 2-dimensional\n",
      " |          A NumPy matrix object with the same shape and containing\n",
      " |          the same data represented by the sparse matrix, with the\n",
      " |          requested memory order. If `out` was passed and was an\n",
      " |          array (rather than a `numpy.matrix`), it will be filled\n",
      " |          with the appropriate values and returned wrapped in a\n",
      " |          `numpy.matrix` object that shares the same memory.\n",
      " |  \n",
      " |  todia(self, copy=False)\n",
      " |      Convert this matrix to sparse DIAgonal format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant dia_matrix.\n",
      " |  \n",
      " |  todok(self, copy=False)\n",
      " |      Convert this matrix to Dictionary Of Keys format.\n",
      " |      \n",
      " |      With copy=False, the data/indices may be shared between this matrix and\n",
      " |      the resultant dok_matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  nnz\n",
      " |      Number of stored values, including explicit zeros.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      count_nonzero : Number of non-zero entries\n",
      " |  \n",
      " |  shape\n",
      " |      Get shape of a matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __array_priority__ = 10.1\n",
      " |  \n",
      " |  ndim = 2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.data._minmax_mixin:\n",
      " |  \n",
      " |  argmax(self, axis=None, out=None)\n",
      " |      Return indices of maximum elements along an axis.\n",
      " |      \n",
      " |      Implicit zero elements are also taken into account. If there are\n",
      " |      several maximum values, the index of the first occurrence is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None}, optional\n",
      " |          Axis along which the argmax is computed. If None (default), index\n",
      " |          of the maximum element in the flatten data is returned.\n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except for\n",
      " |          the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ind : np.matrix or int\n",
      " |          Indices of maximum elements. If matrix, its size along `axis` is 1.\n",
      " |  \n",
      " |  argmin(self, axis=None, out=None)\n",
      " |      Return indices of minimum elements along an axis.\n",
      " |      \n",
      " |      Implicit zero elements are also taken into account. If there are\n",
      " |      several minimum values, the index of the first occurrence is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None}, optional\n",
      " |          Axis along which the argmin is computed. If None (default), index\n",
      " |          of the minimum element in the flatten data is returned.\n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except for\n",
      " |          the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |       ind : np.matrix or int\n",
      " |          Indices of minimum elements. If matrix, its size along `axis` is 1.\n",
      " |  \n",
      " |  max(self, axis=None, out=None)\n",
      " |      Return the maximum of the matrix or maximum along an axis.\n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the sum is computed. The default is to\n",
      " |          compute the maximum over all the matrix elements, returning\n",
      " |          a scalar (i.e. `axis` = `None`).\n",
      " |      \n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except\n",
      " |          for the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amax : coo_matrix or scalar\n",
      " |          Maximum of `a`. If `axis` is None, the result is a scalar value.\n",
      " |          If `axis` is given, the result is a sparse.coo_matrix of dimension\n",
      " |          ``a.ndim - 1``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      min : The minimum value of a sparse matrix along a given axis.\n",
      " |      np.matrix.max : NumPy's implementation of 'max' for matrices\n",
      " |  \n",
      " |  min(self, axis=None, out=None)\n",
      " |      Return the minimum of the matrix or maximum along an axis.\n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {-2, -1, 0, 1, None} optional\n",
      " |          Axis along which the sum is computed. The default is to\n",
      " |          compute the minimum over all the matrix elements, returning\n",
      " |          a scalar (i.e. `axis` = `None`).\n",
      " |      \n",
      " |      out : None, optional\n",
      " |          This argument is in the signature *solely* for NumPy\n",
      " |          compatibility reasons. Do not pass in anything except for\n",
      " |          the default value, as this argument is not used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amin : coo_matrix or scalar\n",
      " |          Minimum of `a`. If `axis` is None, the result is a scalar value.\n",
      " |          If `axis` is given, the result is a sparse.coo_matrix of dimension\n",
      " |          ``a.ndim - 1``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      max : The maximum value of a sparse matrix along a given axis.\n",
      " |      np.matrix.min : NumPy's implementation of 'min' for matrices\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x36980 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How is tweet stored?\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([48, 49, 50, 51, 52, 53], dtype=int32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 49, 50, 51, 52, 53], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-zero indices of terms used in tweet 1.\n",
    "X[1].nonzero()[1]  # col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.make_vocabulary.<locals>.<lambda>()>,\n",
       "            {'power': 0,\n",
       "             'peaker': 1,\n",
       "             'm1w1d3...': 2,\n",
       "             'only': 3,\n",
       "             '1': 4,\n",
       "             'page': 5,\n",
       "             'today': 6,\n",
       "             'but': 7,\n",
       "             'took': 8,\n",
       "             'nearly': 9,\n",
       "             'an': 10,\n",
       "             'hour': 11,\n",
       "             'and': 12,\n",
       "             'a': 13,\n",
       "             'half': 14,\n",
       "             'to': 15,\n",
       "             'complete.': 16,\n",
       "             '#mypeakchallenge2019…': 17,\n",
       "             'https://t.co/pcw71lruek': 18,\n",
       "             'd=my': 19,\n",
       "             'd=husband': 20,\n",
       "             'd=is': 21,\n",
       "             'd=jaime.': 22,\n",
       "             'd=we': 23,\n",
       "             'd=have': 24,\n",
       "             'd=known': 25,\n",
       "             'd=each': 26,\n",
       "             'd=other': 27,\n",
       "             'd=since': 28,\n",
       "             'd=1985,': 29,\n",
       "             'd=got': 30,\n",
       "             'd=married': 31,\n",
       "             'd=in': 32,\n",
       "             'd=1995': 33,\n",
       "             'd=and': 34,\n",
       "             'd=are': 35,\n",
       "             'd=celebrating': 36,\n",
       "             'd=23': 37,\n",
       "             'd=years': 38,\n",
       "             'd=this': 39,\n",
       "             'd=year.': 40,\n",
       "             'd=i': 41,\n",
       "             'd=an': 42,\n",
       "             'd=amazing': 43,\n",
       "             'd=25': 44,\n",
       "             'd=year': 45,\n",
       "             'd=old': 46,\n",
       "             'd=son.': 47,\n",
       "             'its': 48,\n",
       "             'ohdee': 49,\n",
       "             'hot': 50,\n",
       "             'd=inquires:': 51,\n",
       "             'd=prodbyjah24@gmail.com': 52,\n",
       "             'd=#muterkelly': 53,\n",
       "             '@jeepsuzih2': 54,\n",
       "             '@surfermom77': 55,\n",
       "             '@usalovegod': 56,\n",
       "             '@realsugarlily': 57,\n",
       "             '@loriinutah': 58,\n",
       "             '@lvnancy': 59,\n",
       "             '@pinkk9lover': 60,\n",
       "             '@kimberlym1m': 61,\n",
       "             '@gr8tjude_08…': 62,\n",
       "             'https://t.co/7cfhigz3tc': 63,\n",
       "             'because': 64,\n",
       "             'i’m': 65,\n",
       "             'first': 66,\n",
       "             'responder': 67,\n",
       "             'who': 68,\n",
       "             'doesn’t': 69,\n",
       "             'get': 70,\n",
       "             'paid': 71,\n",
       "             'lot': 72,\n",
       "             'save': 73,\n",
       "             'people’s': 74,\n",
       "             'lives': 75,\n",
       "             'd=emergency': 76,\n",
       "             'd=medical': 77,\n",
       "             'd=technician': 78,\n",
       "             'd=emt,': 79,\n",
       "             'd=i’m': 80,\n",
       "             'd=a': 81,\n",
       "             'd=true': 82,\n",
       "             'd=clemson': 83,\n",
       "             'd=tiger': 84,\n",
       "             'd=fan!!': 85,\n",
       "             'd=wedding/event': 86,\n",
       "             'd=planner': 87,\n",
       "             'the': 88,\n",
       "             'fact': 89,\n",
       "             'that': 90,\n",
       "             'new': 91,\n",
       "             'braunfels': 92,\n",
       "             'is': 93,\n",
       "             'having': 94,\n",
       "             'german': 95,\n",
       "             'christmas': 96,\n",
       "             'market': 97,\n",
       "             'this': 98,\n",
       "             'winter': 99,\n",
       "             'makes': 100,\n",
       "             'me': 101,\n",
       "             'so': 102,\n",
       "             'happy.': 103,\n",
       "             'was': 104,\n",
       "             'one': 105,\n",
       "             'of': 106,\n",
       "             'my': 107,\n",
       "             'f…': 108,\n",
       "             'https://t.co/gojr2fojfn': 109,\n",
       "             'd=love': 110,\n",
       "             'd=god,': 111,\n",
       "             'd=others.†': 112,\n",
       "             'd=@arzabalacarlos': 113,\n",
       "             'd=💍': 114,\n",
       "             'hierve': 115,\n",
       "             'la': 116,\n",
       "             'sangre': 117,\n",
       "             'del': 118,\n",
       "             'corajeee': 119,\n",
       "             '😡': 120,\n",
       "             'd=a&b💞': 121,\n",
       "             'd=instagram:aleetorres0606': 122,\n",
       "             '@rboyle31': 123,\n",
       "             'it’s': 124,\n",
       "             'favorite': 125,\n",
       "             '@davematthewsbnd': 126,\n",
       "             'song': 127,\n",
       "             'it': 128,\n",
       "             'brings': 129,\n",
       "             'tears': 130,\n",
       "             'every': 131,\n",
       "             'time': 132,\n",
       "             'i': 133,\n",
       "             'hear': 134,\n",
       "             'it.': 135,\n",
       "             'd=magic': 136,\n",
       "             'd=bean': 137,\n",
       "             'd=buyer.': 138,\n",
       "             'd=@tulsampa': 139,\n",
       "             'd=student,': 140,\n",
       "             'd=@cap_tulsa': 141,\n",
       "             'd=graphic': 142,\n",
       "             'd=designer,': 143,\n",
       "             'd=@codefortulsa': 144,\n",
       "             'd=captain,': 145,\n",
       "             'd=@techlahoma': 146,\n",
       "             'd=board,': 147,\n",
       "             'd=2014': 148,\n",
       "             'd=@nextcityorg': 149,\n",
       "             'd=vanguard.': 150,\n",
       "             'd=opinions': 151,\n",
       "             'd=own.': 152,\n",
       "             '✌🏻see': 153,\n",
       "             'ya': 154,\n",
       "             'later,': 155,\n",
       "             'texas.': 156,\n",
       "             '✌🏻': 157,\n",
       "             '✈️': 158,\n",
       "             'd=patriot.': 159,\n",
       "             'd=gov/mil': 160,\n",
       "             'd=contractor.': 161,\n",
       "             'd=stop': 162,\n",
       "             'd=bullets': 163,\n",
       "             'd=&': 164,\n",
       "             'd=bombs.': 165,\n",
       "             'd=born/raised': 166,\n",
       "             'd=texas.': 167,\n",
       "             'd=lover': 168,\n",
       "             'd=of': 169,\n",
       "             'd=whiskey': 170,\n",
       "             'd=1911s.': 171,\n",
       "             'd=sometimes': 172,\n",
       "             'd=play': 173,\n",
       "             'd=soccer,': 174,\n",
       "             'd=destiny,': 175,\n",
       "             'd=or': 176,\n",
       "             'd=myself.': 177,\n",
       "             '@juliadavisnews': 178,\n",
       "             'crooks': 179,\n",
       "             'always': 180,\n",
       "             'attempt': 181,\n",
       "             'cover': 182,\n",
       "             'their': 183,\n",
       "             'tracks': 184,\n",
       "             'clever': 185,\n",
       "             'ones': 186,\n",
       "             'do': 187,\n",
       "             'before': 188,\n",
       "             'they': 189,\n",
       "             'are': 190,\n",
       "             'caught,': 191,\n",
       "             'not': 192,\n",
       "             'after.': 193,\n",
       "             '@anamerican4': 194,\n",
       "             '@realdonaldtrump': 195,\n",
       "             '@vp': 196,\n",
       "             'https://t.co/6n14vckxpb': 197,\n",
       "             'd=people': 198,\n",
       "             'd=would': 199,\n",
       "             'd=rather': 200,\n",
       "             'd=believe': 201,\n",
       "             'd=things': 202,\n",
       "             'd=that': 203,\n",
       "             'd=wrong': 204,\n",
       "             'd=than': 205,\n",
       "             'd=make': 206,\n",
       "             'd=them': 207,\n",
       "             'd=uncomfortable.': 208,\n",
       "             'd=https://scienceofdoom.com/roadmap/atmospheric-radiation-and-': 209,\n",
       "             '@abc7ny': 210,\n",
       "             '@hoeeness': 211,\n",
       "             'd=28,': 212,\n",
       "             'd=cali': 213,\n",
       "             'd=🇯🇲🇯🇲': 214,\n",
       "             'd=antisocial': 215,\n",
       "             'd=extrovert': 216,\n",
       "             '@eaglegryphon': 217,\n",
       "             '#maniacal': 218,\n",
       "             'available': 219,\n",
       "             'for': 220,\n",
       "             'pre': 221,\n",
       "             'order': 222,\n",
       "             'yet': 223,\n",
       "             'somewhere?': 224,\n",
       "             ':)': 225,\n",
       "             'd=board': 226,\n",
       "             'd=games,': 227,\n",
       "             'd=cthulhu': 228,\n",
       "             'd=cultist,': 229,\n",
       "             'd=dice': 230,\n",
       "             'd=chucker,': 231,\n",
       "             'd=one': 232,\n",
       "             'd=half': 233,\n",
       "             'd=@rolldoubles': 234,\n",
       "             'd=podcast,': 235,\n",
       "             'd=retweeter': 236,\n",
       "             'd=@ledergames,': 237,\n",
       "             'd=founder': 238,\n",
       "             'd=@saintpaulgames': 239,\n",
       "             '@gregg28131315': 240,\n",
       "             '@krystalball': 241,\n",
       "             '@berniesanders': 242,\n",
       "             '@esaagar': 243,\n",
       "             'at': 244,\n",
       "             '80.': 245,\n",
       "             'same': 246,\n",
       "             'day.': 247,\n",
       "             'blood': 248,\n",
       "             'clot': 249,\n",
       "             'risk': 250,\n",
       "             'high': 251,\n",
       "             'age.': 252,\n",
       "             'i…': 253,\n",
       "             'https://t.co/a2ld6qdqlx': 254,\n",
       "             'd=happily': 255,\n",
       "             'd=recruiting': 256,\n",
       "             'd=#boston!': 257,\n",
       "             'd=loving': 258,\n",
       "             'd=life,': 259,\n",
       "             'd=travel,': 260,\n",
       "             'd=food': 261,\n",
       "             'd=some': 262,\n",
       "             'd=politics.': 263,\n",
       "             'd=posts': 264,\n",
       "             'd=be': 265,\n",
       "             'd=good': 266,\n",
       "             'd=to': 267,\n",
       "             'd=other!': 268,\n",
       "             '🎮💙': 269,\n",
       "             'https://t.co/icortovllz': 270,\n",
       "             'd=blackpink': 271,\n",
       "             'd=stan': 272,\n",
       "             'd=/': 273,\n",
       "             'd=gaymer': 274,\n",
       "             'got': 275,\n",
       "             'speak': 276,\n",
       "             'in': 277,\n",
       "             'front': 278,\n",
       "             'interim': 279,\n",
       "             'joint': 280,\n",
       "             'committee': 281,\n",
       "             'on': 282,\n",
       "             'licensing': 283,\n",
       "             'occupations': 284,\n",
       "             'top…': 285,\n",
       "             'https://t.co/gqlie2tuzb': 286,\n",
       "             'd=united': 287,\n",
       "             'd=states': 288,\n",
       "             'd=ambassador': 289,\n",
       "             'd=latveria': 290,\n",
       "             '@tigresfemenil': 291,\n",
       "             '@ligabbvafemenil': 292,\n",
       "             '@houstondash': 293,\n",
       "             'ahí': 294,\n",
       "             'estaré': 295,\n",
       "             'alentando': 296,\n",
       "             'como': 297,\n",
       "             'desde': 298,\n",
       "             'el': 299,\n",
       "             'día': 300,\n",
       "             'de': 301,\n",
       "             'este': 302,\n",
       "             'gran': 303,\n",
       "             'equipo!!': 304,\n",
       "             '🇸🇪🇺🇦🐯💙💛😉': 305,\n",
       "             '#tigresuanl': 306,\n",
       "             'd=regio🤠': 307,\n",
       "             'd=||': 308,\n",
       "             'd=tigres': 309,\n",
       "             'd=de': 310,\n",
       "             'd=la': 311,\n",
       "             'd=uanl🇺🇦🐯': 312,\n",
       "             'd=naty': 313,\n",
       "             'd=miramontes': 314,\n",
       "             'd=#31😍💙💛🐯': 315,\n",
       "             'd=periodista': 316,\n",
       "             'd=deportivo': 317,\n",
       "             'd=en': 318,\n",
       "             'd=proceso🔄': 319,\n",
       "             '@lindseygrahamsc': 320,\n",
       "             'take': 321,\n",
       "             'gloves': 322,\n",
       "             'off': 323,\n",
       "             'dems': 324,\n",
       "             'need': 325,\n",
       "             'be': 326,\n",
       "             'subpoenaed': 327,\n",
       "             'let’s': 328,\n",
       "             'testimonies': 329,\n",
       "             'under': 330,\n",
       "             'oath': 331,\n",
       "             'by': 332,\n",
       "             'pel…': 333,\n",
       "             'https://t.co/wdst9wgj3n': 334,\n",
       "             'marry': 335,\n",
       "             'magdalin': 336,\n",
       "             'emily': 337,\n",
       "             'tryed': 338,\n",
       "             'warn': 339,\n",
       "             'her': 340,\n",
       "             'she': 341,\n",
       "             'could': 342,\n",
       "             'crucified': 343,\n",
       "             \"d=i'm\": 344,\n",
       "             'd=st.': 345,\n",
       "             'd=mikel': 346,\n",
       "             '@genesimmons': 347,\n",
       "             'you': 348,\n",
       "             'blessed': 349,\n",
       "             'have': 350,\n",
       "             'your': 351,\n",
       "             'wonderful': 352,\n",
       "             'family': 353,\n",
       "             'help': 354,\n",
       "             'recover': 355,\n",
       "             'even': 356,\n",
       "             'quicker': 357,\n",
       "             'gene!': 358,\n",
       "             'hope': 359,\n",
       "             'well': 360,\n",
       "             'again': 361,\n",
       "             'very': 362,\n",
       "             'soon!@': 363,\n",
       "             'd=animal': 364,\n",
       "             'd=rock': 365,\n",
       "             'd=music': 366,\n",
       "             'd=lover!': 367,\n",
       "             'd=kiss': 368,\n",
       "             'd=rules': 369,\n",
       "             '@barbmcquade': 370,\n",
       "             '#gopcoma': 371,\n",
       "             'd=51': 372,\n",
       "             'd=prom': 373,\n",
       "             'd=date,': 374,\n",
       "             'd=blessed,': 375,\n",
       "             'd=2': 376,\n",
       "             'd=sons,': 377,\n",
       "             'd=3': 378,\n",
       "             'd=grand': 379,\n",
       "             'd=kids,': 380,\n",
       "             'd=50+': 381,\n",
       "             'd=trips': 382,\n",
       "             'd=europe,': 383,\n",
       "             'd=porsche': 384,\n",
       "             'd=#': 385,\n",
       "             'd=3,': 386,\n",
       "             'd=yogi,': 387,\n",
       "             'd=speaking': 388,\n",
       "             'd=truth': 389,\n",
       "             'd=power.': 390,\n",
       "             \"haven't\": 391,\n",
       "             'done': 392,\n",
       "             'anything': 393,\n",
       "             'since': 394,\n",
       "             'russia': 395,\n",
       "             'elected': 396,\n",
       "             'presidency.': 397,\n",
       "             \"you're\": 398,\n",
       "             'pointing': 399,\n",
       "             'cro…': 400,\n",
       "             'https://t.co/lwtvzobzok': 401,\n",
       "             'd=clinical': 402,\n",
       "             'd=microbiologist.': 403,\n",
       "             'd=former': 404,\n",
       "             'd=detroiter,': 405,\n",
       "             'd=retired': 406,\n",
       "             'd=usaf': 407,\n",
       "             'd=~it': 408,\n",
       "             'd=never': 409,\n",
       "             'd=weird': 410,\n",
       "             'd=enough': 411,\n",
       "             'd=for': 412,\n",
       "             'd=me': 413,\n",
       "             'd=~': 414,\n",
       "             'd=hunter': 415,\n",
       "             'd=s.': 416,\n",
       "             'd=thompson': 417,\n",
       "             'demented': 418,\n",
       "             'mind!': 419,\n",
       "             '@carolynruffles': 420,\n",
       "             'carolyn-': 421,\n",
       "             'thanks': 422,\n",
       "             'following.': 423,\n",
       "             'appreciate': 424,\n",
       "             'how’s': 425,\n",
       "             'week': 426,\n",
       "             'going?': 427,\n",
       "             'd=🚀': 428,\n",
       "             'd=adventurer:': 429,\n",
       "             'd=feel': 430,\n",
       "             'd=younger': 431,\n",
       "             'd=longer': 432,\n",
       "             'd=♥️': 433,\n",
       "             'd=🧘🏼\\u200d♂️': 434,\n",
       "             'd=mindfulness': 435,\n",
       "             'd=fan': 436,\n",
       "             'd=📖': 437,\n",
       "             'd=reader': 438,\n",
       "             'd=gamer': 439,\n",
       "             'd=🎮': 440,\n",
       "             'd=caregiver': 441,\n",
       "             'd=👍👍👍': 442,\n",
       "             'd=positive': 443,\n",
       "             'd=engaging.': 444,\n",
       "             'd=tell': 445,\n",
       "             'd=your': 446,\n",
       "             'd=story!': 447,\n",
       "             'd=#burbank': 448,\n",
       "             'how': 449,\n",
       "             'man': 450,\n",
       "             'still': 451,\n",
       "             'head': 452,\n",
       "             'coach?': 453,\n",
       "             'just': 454,\n",
       "             'last': 455,\n",
       "             'name?': 456,\n",
       "             'd=fantasy': 457,\n",
       "             'd=sports': 458,\n",
       "             'd=writer': 459,\n",
       "             'd=at': 460,\n",
       "             'd=@fantrax.': 461,\n",
       "             'd=rankings': 462,\n",
       "             'd=@fantasypros.': 463,\n",
       "             'd=carla': 464,\n",
       "             'd=was': 465,\n",
       "             'd=the': 466,\n",
       "             'd=queen.': 467,\n",
       "             'd=#banthewin.': 468,\n",
       "             'd=#sfb9': 469,\n",
       "             'd=glass': 470,\n",
       "             'd=joe': 471,\n",
       "             'd=division': 472,\n",
       "             'd=🥊': 473,\n",
       "             'exactly': 474,\n",
       "             'wanted': 475,\n",
       "             'mueller': 476,\n",
       "             'investigation': 477,\n",
       "             'longer': 478,\n",
       "             'try': 479,\n",
       "             'themselves': 480,\n",
       "             'ag': 481,\n",
       "             'barr': 482,\n",
       "             'stopped': 483,\n",
       "             'their…': 484,\n",
       "             'https://t.co/krp9oxxa4o': 485,\n",
       "             'd=vietnam': 486,\n",
       "             'd=veteran': 487,\n",
       "             'd=magaveteran': 488,\n",
       "             '@toripaulman': 489,\n",
       "             '@melrobbins': 490,\n",
       "             'great': 491,\n",
       "             'way': 492,\n",
       "             'frame': 493,\n",
       "             'negative': 494,\n",
       "             'thoughts!': 495,\n",
       "             'tip!': 496,\n",
       "             'd=insatiable': 497,\n",
       "             'd=curiosity': 498,\n",
       "             'd=drives': 499,\n",
       "             'd=lifelong': 500,\n",
       "             'd=learning.': 501,\n",
       "             'd=which': 502,\n",
       "             'd=means': 503,\n",
       "             'd=find': 504,\n",
       "             'd=something': 505,\n",
       "             'd=interesting': 506,\n",
       "             'd=nearly': 507,\n",
       "             'd=everything': 508,\n",
       "             'd=everyone!': 509,\n",
       "             'what': 510,\n",
       "             'college': 511,\n",
       "             'air': 512,\n",
       "             'making': 513,\n",
       "             'feel': 514,\n",
       "             'sad': 515,\n",
       "             'depressed?': 516,\n",
       "             'ion': 517,\n",
       "             'like': 518,\n",
       "             'bit.': 519,\n",
       "             'vent': 520,\n",
       "             'session': 521,\n",
       "             'asap': 522,\n",
       "             'd=isu🎈god': 523,\n",
       "             'd=first✝️': 524,\n",
       "             'd=redelite💃🏾': 525,\n",
       "             'd=bgc👑': 526,\n",
       "             '@valisjason': 527,\n",
       "             '@billybragg': 528,\n",
       "             '#rankedchoicevoting': 529,\n",
       "             'offers': 530,\n",
       "             'many': 531,\n",
       "             'benefits': 532,\n",
       "             'voters': 533,\n",
       "             '-': 534,\n",
       "             'no': 535,\n",
       "             'split': 536,\n",
       "             'votes,': 537,\n",
       "             'cheaper': 538,\n",
       "             'campaigns,…': 539,\n",
       "             'https://t.co/ti9oiwth4v': 540,\n",
       "             'd=quaker': 541,\n",
       "             'd=gal': 542,\n",
       "             'd=working': 543,\n",
       "             'd=systems': 544,\n",
       "             'd=strategies': 545,\n",
       "             'd=advance': 546,\n",
       "             'd=women’s': 547,\n",
       "             'd=representation': 548,\n",
       "             'd=leadership.': 549,\n",
       "             'd=director': 550,\n",
       "             'd=@repwomen': 551,\n",
       "             'd=democracy|#rcv': 552,\n",
       "             'd=champ': 553,\n",
       "             'd=@rob_richie': 554,\n",
       "             'beautiful': 555,\n",
       "             'day': 556,\n",
       "             'monterey': 557,\n",
       "             'bay,': 558,\n",
       "             'gateway': 559,\n",
       "             'big': 560,\n",
       "             'sur': 561,\n",
       "             'coast': 562,\n",
       "             'https://t.co/gtj2rvepka': 563,\n",
       "             'd=earthquake': 564,\n",
       "             'd=aficionado': 565,\n",
       "             'd=personally': 566,\n",
       "             'd=professionally.': 567,\n",
       "             'd=also': 568,\n",
       "             'd=lots': 569,\n",
       "             'd=about': 570,\n",
       "             'd=clouds': 571,\n",
       "             'd=trains': 572,\n",
       "             'd=sustainable': 573,\n",
       "             'd=transit,': 574,\n",
       "             'd=it': 575,\n",
       "             'd=turns': 576,\n",
       "             'd=out.': 577,\n",
       "             'd=luuuvs': 578,\n",
       "             'd=maps': 579,\n",
       "             'd=🏳️\\u200d🌈': 580,\n",
       "             'd=he/him': 581,\n",
       "             '@rubymay1993': 582,\n",
       "             'word': 583,\n",
       "             'right': 584,\n",
       "             'here!!!': 585,\n",
       "             '⬆️': 586,\n",
       "             'modern': 587,\n",
       "             'farmhouse': 588,\n",
       "             'has': 589,\n",
       "             'all': 590,\n",
       "             '😍!': 591,\n",
       "             '25': 592,\n",
       "             'mins': 593,\n",
       "             'from': 594,\n",
       "             '#downtowngreenville': 595,\n",
       "             '&amp;': 596,\n",
       "             'around': 597,\n",
       "             'corner': 598,\n",
       "             'from…': 599,\n",
       "             'https://t.co/vodgwx7wob': 600,\n",
       "             'd=residential': 601,\n",
       "             'd=realtor®️,': 602,\n",
       "             'd=coldwell': 603,\n",
       "             'd=banker': 604,\n",
       "             'd=caine,': 605,\n",
       "             'd=upstate': 606,\n",
       "             'd=south': 607,\n",
       "             'd=carolina': 608,\n",
       "             'our': 609,\n",
       "             'amazing': 610,\n",
       "             'team!': 611,\n",
       "             'd=cardiovascular': 612,\n",
       "             'd=disease': 613,\n",
       "             'd=fellow': 614,\n",
       "             'd=@einsteinhealth': 615,\n",
       "             'd=phl.': 616,\n",
       "             'd=aspiring': 617,\n",
       "             'd=ep.': 618,\n",
       "             'd=f1': 619,\n",
       "             'd=fan.': 620,\n",
       "             'd=golfer.': 621,\n",
       "             'd=asu.': 622,\n",
       "             'd=opinions/thoughts': 623,\n",
       "             'd=rts': 624,\n",
       "             'd==/=': 625,\n",
       "             'd=endorsement.': 626,\n",
       "             '@smithreads': 627,\n",
       "             '@fisd_libraries': 628,\n",
       "             '@smithelem_noel': 629,\n",
       "             '@penguinbooks': 630,\n",
       "             'me!!!!': 631,\n",
       "             'd=nyt/wsj/usa': 632,\n",
       "             'd=today': 633,\n",
       "             'd=bestselling': 634,\n",
       "             'd=author.': 635,\n",
       "             'd=tv+movies:': 636,\n",
       "             'd=last': 637,\n",
       "             'd=kids': 638,\n",
       "             'd=on': 639,\n",
       "             'd=earth': 640,\n",
       "             'd=(@netflix),': 641,\n",
       "             'd=v.f.w.': 642,\n",
       "             'd=(@fangoria': 643,\n",
       "             'd=),': 644,\n",
       "             'd=eerie': 645,\n",
       "             'd=elementary,': 646,\n",
       "             'd=mister': 647,\n",
       "             'd=shivers.': 648,\n",
       "             'd=kind,': 649,\n",
       "             'd=get': 650,\n",
       "             'd=happy.': 651,\n",
       "             '@whitneyarner': 652,\n",
       "             'really,': 653,\n",
       "             'we': 654,\n",
       "             'should': 655,\n",
       "             'lucky': 656,\n",
       "             'as': 657,\n",
       "             'own': 658,\n",
       "             'personal': 659,\n",
       "             'dick': 660,\n",
       "             'warlock': 661,\n",
       "             'd=computer': 662,\n",
       "             'd=nerd.': 663,\n",
       "             'd=japan': 664,\n",
       "             'd=dork.': 665,\n",
       "             'd=horror': 666,\n",
       "             'd=geek.': 667,\n",
       "             'd=comic': 668,\n",
       "             'd=book': 669,\n",
       "             'd=guy.': 670,\n",
       "             'd=sci': 671,\n",
       "             'd=fi': 672,\n",
       "             'd=fanboy.': 673,\n",
       "             'd=not': 674,\n",
       "             'd=necessarily': 675,\n",
       "             'd=order.': 676,\n",
       "             'd=enthusiast,': 677,\n",
       "             'd=connoisseur.': 678,\n",
       "             'd=banner': 679,\n",
       "             'd=by': 680,\n",
       "             'd=@bedsafely': 681,\n",
       "             'oh': 682,\n",
       "             'if': 683,\n",
       "             'zoom': 684,\n",
       "             'can': 685,\n",
       "             'see': 686,\n",
       "             'also': 687,\n",
       "             'stole': 688,\n",
       "             '@ellorysmith’s': 689,\n",
       "             'nail': 690,\n",
       "             'color': 691,\n",
       "             'which': 692,\n",
       "             'would': 693,\n",
       "             'put': 694,\n",
       "             '#1': 695,\n",
       "             'list': 696,\n",
       "             'of…': 697,\n",
       "             'https://t.co/bps7izggif': 698,\n",
       "             'd=writer.': 699,\n",
       "             'd=illustrator.': 700,\n",
       "             'd=circumstantially': 701,\n",
       "             'd=funny.': 702,\n",
       "             'd=program': 703,\n",
       "             'd=director:': 704,\n",
       "             'd=@denverwrites': 705,\n",
       "             'd=sc:': 706,\n",
       "             'd=kevinpeterson': 707,\n",
       "             'd=http://instagram.com/kevinpeterson': 708,\n",
       "             '@jazstory': 709,\n",
       "             'recommendations?': 710,\n",
       "             'd=nurse.': 711,\n",
       "             'd=crone.': 712,\n",
       "             'd=witch.': 713,\n",
       "             'd=granny.': 714,\n",
       "             'd=mother.': 715,\n",
       "             \"d=fella's\": 716,\n",
       "             'd=lady.': 717,\n",
       "             'd=feline': 718,\n",
       "             'd=servant.': 719,\n",
       "             'd=fresh': 720,\n",
       "             'd=out': 721,\n",
       "             'd=fucks.': 722,\n",
       "             'd=she/her.': 723,\n",
       "             '@sleepybear408': 724,\n",
       "             'or': 725,\n",
       "             '😂': 726,\n",
       "             'https://t.co/kvtvwpbsbw': 727,\n",
       "             'd=blog': 728,\n",
       "             'd=@nothingbut9ers': 729,\n",
       "             'd=co-host': 730,\n",
       "             'd=@starting5tv': 731,\n",
       "             'd=show.': 732,\n",
       "             'd=checkout': 733,\n",
       "             'd=wayne’s': 734,\n",
       "             'd=rant': 735,\n",
       "             'd=pod': 736,\n",
       "             'd=@_celtics_center': 737,\n",
       "             'd=#49ers': 738,\n",
       "             'd=#celtics': 739,\n",
       "             'd=#mets': 740,\n",
       "             'd=#goblue': 741,\n",
       "             'd=#huskies': 742,\n",
       "             'd=#nb9ers': 743,\n",
       "             '@astros': 744,\n",
       "             '#cutiepatootie': 745,\n",
       "             '@mrtipton33': 746,\n",
       "             '@9stayup': 747,\n",
       "             'said': 748,\n",
       "             'd=#baseball': 749,\n",
       "             'd=#dad': 750,\n",
       "             'd=#braves': 751,\n",
       "             'd=#marvel': 752,\n",
       "             'd=#chopon': 753,\n",
       "             'd=#type1diabetic.': 754,\n",
       "             'd=#iloveyou3000.': 755,\n",
       "             'd=life.': 756,\n",
       "             'd=respect': 757,\n",
       "             'd=everyones': 758,\n",
       "             'd=political': 759,\n",
       "             'd=opinion.': 760,\n",
       "             'd=father': 761,\n",
       "             'constantly': 762,\n",
       "             'posting': 763,\n",
       "             'others': 764,\n",
       "             'here': 765,\n",
       "             'about': 766,\n",
       "             'myself': 767,\n",
       "             'once': 768,\n",
       "             '🤧': 769,\n",
       "             'https://t.co/uyezra89qq': 770,\n",
       "             'd=21': 771,\n",
       "             'd=✨': 772,\n",
       "             'd=photographer': 773,\n",
       "             'd=📸': 774,\n",
       "             'd=dm': 775,\n",
       "             'd=if': 776,\n",
       "             'd=ya': 777,\n",
       "             'd=ever': 778,\n",
       "             'd=need': 779,\n",
       "             'd=pics': 780,\n",
       "             'd=😋': 781,\n",
       "             'hurricanes': 782,\n",
       "             'breakfast': 783,\n",
       "             'arobb44': 784,\n",
       "             '@': 785,\n",
       "             'pat': 786,\n",
       "             \"o'briens\": 787,\n",
       "             'san': 788,\n",
       "             'antonio': 789,\n",
       "             'https://t.co/m0bx0tp5ag': 790,\n",
       "             'd=badass': 791,\n",
       "             '@realsaavedra': 792,\n",
       "             'tory': 793,\n",
       "             'side?': 794,\n",
       "             '😄': 795,\n",
       "             '@abc': 796,\n",
       "             'wishes': 797,\n",
       "             'speedy': 798,\n",
       "             'recovery': 799,\n",
       "             'sen.': 800,\n",
       "             'sanders.': 801,\n",
       "             'carson': 802,\n",
       "             'wentz': 803,\n",
       "             'says': 804,\n",
       "             '#eagles': 805,\n",
       "             'offense': 806,\n",
       "             'pressure': 807,\n",
       "             'score': 808,\n",
       "             'more': 809,\n",
       "             'points': 810,\n",
       "             'with': 811,\n",
       "             'injuries': 812,\n",
       "             'defen…': 813,\n",
       "             'https://t.co/dikjrcfkhh': 814,\n",
       "             'd=@kywnewsradio': 815,\n",
       "             'd=morning': 816,\n",
       "             'd=anchor': 817,\n",
       "             'd=@wfan660/@1010wins': 818,\n",
       "             'd=@sportsradiowip': 819,\n",
       "             'd=contributor': 820,\n",
       "             'd=|': 821,\n",
       "             'd=any': 822,\n",
       "             'd=views': 823,\n",
       "             'd=expressed': 824,\n",
       "             'd=mine': 825,\n",
       "             'd=retweets': 826,\n",
       "             'd=endorsements': 827,\n",
       "             'long': 828,\n",
       "             'application': 829,\n",
       "             '😭': 830,\n",
       "             'd=rest': 831,\n",
       "             'd=easy': 832,\n",
       "             'd=dad': 833,\n",
       "             'd=les': 834,\n",
       "             'd=jdc': 835,\n",
       "             'd=forever': 836,\n",
       "             'attn:': 837,\n",
       "             '#lsu': 838,\n",
       "             '#saints': 839,\n",
       "             'fans': 840,\n",
       "             'd=saints': 841,\n",
       "             'd=@nolanews': 842,\n",
       "             'd=@theadvocatebr': 843,\n",
       "             'd=•': 844,\n",
       "             'd=still': 845,\n",
       "             'd=tweets': 846,\n",
       "             'd=lsu,': 847,\n",
       "             'd=montana,': 848,\n",
       "             'd=kansas': 849,\n",
       "             'd=nebraska': 850,\n",
       "             'd=home': 851,\n",
       "             'd=@kujournalism': 852,\n",
       "             'd=grad': 853,\n",
       "             'd=who': 854,\n",
       "             'd=hates': 855,\n",
       "             'd=sandstorm': 856,\n",
       "             'promises': 857,\n",
       "             'made': 858,\n",
       "             'kept.': 859,\n",
       "             'flat': 860,\n",
       "             'out': 861,\n",
       "             'd=hard': 862,\n",
       "             'd=supporting': 863,\n",
       "             'd=family,': 864,\n",
       "             'd=towards': 865,\n",
       "             'd=better': 866,\n",
       "             'd=future,': 867,\n",
       "             'd=always': 868,\n",
       "             'd=god': 869,\n",
       "             'd=fearing': 870,\n",
       "             'd=man.': 871,\n",
       "             'd=christ~family~me': 872,\n",
       "             'd=joined': 873,\n",
       "             'd=twitter': 874,\n",
       "             'd=bc': 875,\n",
       "             'd=president': 876,\n",
       "             'd=trump': 877,\n",
       "             '@portlandval': 878,\n",
       "             '@reallyserioso': 879,\n",
       "             'pete': 880,\n",
       "             'told': 881,\n",
       "             'reporters': 882,\n",
       "             'early': 883,\n",
       "             'he’s': 884,\n",
       "             'running': 885,\n",
       "             '“values”': 886,\n",
       "             'policies,': 887,\n",
       "             'until': 888,\n",
       "             'he': 889,\n",
       "             'started': 890,\n",
       "             'copying': 891,\n",
       "             'policies...': 892,\n",
       "             'd=sports/events/portraits': 893,\n",
       "             'd=https://www.amyslifephotography.com': 894,\n",
       "             '@gasketgirllife': 895,\n",
       "             '@simpson1fn': 896,\n",
       "             '@ida_skibenes': 897,\n",
       "             'show': 898,\n",
       "             'some': 899,\n",
       "             'compassion': 900,\n",
       "             'people': 901,\n",
       "             'iqs': 902,\n",
       "             'sixties': 903,\n",
       "             'allowed': 904,\n",
       "             'twitter': 905,\n",
       "             'd=msgt.': 906,\n",
       "             'd=retired.': 907,\n",
       "             'd=grown': 908,\n",
       "             'd=men': 909,\n",
       "             'd=1982.': 910,\n",
       "             'feeling': 911,\n",
       "             'sick': 912,\n",
       "             'dog': 913,\n",
       "             'trip': 914,\n",
       "             'london': 915,\n",
       "             'friday...': 916,\n",
       "             'hotel': 917,\n",
       "             'non-refundable.': 918,\n",
       "             'bought': 919,\n",
       "             'emer…': 920,\n",
       "             'https://t.co/vfxp2tcmrq': 921,\n",
       "             '@johncardillo': 922,\n",
       "             '@krystalhiller': 923,\n",
       "             'stop': 924,\n",
       "             'putting': 925,\n",
       "             'jiffy': 926,\n",
       "             'up': 927,\n",
       "             'tookus': 928,\n",
       "             'd=cuban': 929,\n",
       "             'd=birth': 930,\n",
       "             'd=american': 931,\n",
       "             'd=heart': 932,\n",
       "             'd=fmf': 933,\n",
       "             'd=navy': 934,\n",
       "             'd=corpsman,1st': 935,\n",
       "             'd=mardiv,1stmedbn-1stmaw-vma-226/332': 936,\n",
       "             'd=usmc': 937,\n",
       "             'd=semper': 938,\n",
       "             'd=fi-no': 939,\n",
       "             'd=child': 940,\n",
       "             'd=abuse.': 941,\n",
       "             'd=am🇺🇸⛑': 942,\n",
       "             \"i'm\": 943,\n",
       "             'pearl/arts': 944,\n",
       "             'district': 945,\n",
       "             'station': 946,\n",
       "             '(dart': 947,\n",
       "             'rail)': 948,\n",
       "             '@dartmedia': 949,\n",
       "             'dallas,': 950,\n",
       "             'tx': 951,\n",
       "             'https://t.co/v8zcregodf': 952,\n",
       "             'd=openly': 953,\n",
       "             'd=gay': 954,\n",
       "             'd=atheist': 955,\n",
       "             'd=ghetto': 956,\n",
       "             'd=dallas.': 957,\n",
       "             'd=liked': 958,\n",
       "             'd=youtube': 959,\n",
       "             'd=videos': 960,\n",
       "             'd=me.': 961,\n",
       "             'd=#punchsjws.': 962,\n",
       "             '@theautumnwind80': 963,\n",
       "             'either': 964,\n",
       "             'us': 965,\n",
       "             'against': 966,\n",
       "             'us.': 967,\n",
       "             'exceptions,': 968,\n",
       "             'excuses.': 969,\n",
       "             '@kinks': 970,\n",
       "             'damn': 971,\n",
       "             'now': 972,\n",
       "             'fucked': 973,\n",
       "             'bag': 974,\n",
       "             '🤦🏻\\u200d♂️😂': 975,\n",
       "             'd=place': 976,\n",
       "             'd=within': 977,\n",
       "             'd=mind.': 978,\n",
       "             '@repadamschiff': 979,\n",
       "             'hey': 980,\n",
       "             'adam': 981,\n",
       "             'seen': 982,\n",
       "             'those': 983,\n",
       "             'pictures': 984,\n",
       "             'naked': 985,\n",
       "             'trump': 986,\n",
       "             'yet😂😂😂?': 987,\n",
       "             '@mack7mle': 988,\n",
       "             '@7themc': 989,\n",
       "             'think': 990,\n",
       "             'irrelevant.': 991,\n",
       "             'fault': 992,\n",
       "             'makin': 993,\n",
       "             'clear,': 994,\n",
       "             'chief': 995,\n",
       "             'd=creator': 996,\n",
       "             'd=#ncat': 997,\n",
       "             'd=alum': 998,\n",
       "             'd=#ncatfootball': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term counts for tweet 1.\n",
    "X[1].data  # \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# What word does each term index correspond to?\n",
    "# Convert term->index dict into index->term dict\n",
    "index2term = {i: t for t, i in vocabulary.items()}\n",
    "print(index2term[48])\n",
    "print(X[1, 48])\n",
    "# So, the term \"its\" (index 48) appears in user 1's tweet one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i appears two times.\n",
    "print(index2term[21])\n",
    "print(X[1, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Its ohdee hot'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do CSR matrices access row values?\n",
    "\n",
    "Recall:\n",
    "\n",
    "CSR Matrix is an object with three attributes: \n",
    "- **val:** $\\{1,2,1,1\\}$  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *list of all non-zero values*  \n",
    "- **col_ind:** $\\{0,3,0,1\\}$ &nbsp; *column index for each non-zero value* (e.g., first non-zero value (1) is in column 0) \n",
    "- **row_ptr (ind_ptr):** $\\{0,1,2\\}$ &nbsp;&nbsp;&nbsp; *index into **col_ind** where each row starts* (e.g., tweet3, term1 corresponds to col_ind[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200, 300, 400])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall: numpy array slices.\n",
    "import numpy as np\n",
    "a = np.array([0, 100, 200, 300, 400, 500])\n",
    "a[2:5]  # get elements at positions 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 1 starts at col_ind= 48\n",
      "tweet 2 starts at col_ind= 54\n",
      "so, the columns that are non-zero for tweet 1 are:\n",
      "[48 49 50 51 52 53]\n",
      "and the data associated with those cells are:\n",
      "[1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('tweet 1 starts at col_ind=', X.indptr[1])\n",
    "print('tweet 2 starts at col_ind=', X.indptr[2])\n",
    "print('so, the columns that are non-zero for tweet 1 are:')\n",
    "print(X.indices[X.indptr[1]:X.indptr[2]])\n",
    "print('and the data associated with those cells are:')\n",
    "print(X.data[X.indptr[1]:X.indptr[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 0:\n",
      "   (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 13)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 16)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 19)\t2.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 24)\t2.0\n",
      "  (0, 25)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 30)\t1.0\n",
      "  (0, 31)\t1.0\n",
      "  (0, 32)\t1.0\n",
      "  (0, 33)\t1.0\n",
      "  (0, 34)\t1.0\n",
      "  (0, 35)\t1.0\n",
      "  (0, 36)\t1.0\n",
      "  (0, 37)\t1.0\n",
      "  (0, 38)\t1.0\n",
      "  (0, 39)\t1.0\n",
      "  (0, 40)\t1.0\n",
      "  (0, 41)\t1.0\n",
      "  (0, 42)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 44)\t1.0\n",
      "  (0, 45)\t1.0\n",
      "  (0, 46)\t1.0\n",
      "  (0, 47)\t1.0 \n",
      "\n",
      "tweet 1:\n",
      "   (0, 48)\t1.0\n",
      "  (0, 49)\t1.0\n",
      "  (0, 50)\t1.0\n",
      "  (0, 51)\t1.0\n",
      "  (0, 52)\t1.0\n",
      "  (0, 53)\t1.0 \n",
      "\n",
      "tweet 2:\n",
      "   (0, 54)\t1.0\n",
      "  (0, 55)\t1.0\n",
      "  (0, 56)\t1.0\n",
      "  (0, 57)\t1.0\n",
      "  (0, 58)\t1.0\n",
      "  (0, 59)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 61)\t1.0\n",
      "  (0, 62)\t1.0\n",
      "  (0, 63)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print('tweet 0:\\n', X[0], '\\n')\n",
    "print('tweet 1:\\n', X[1], '\\n')\n",
    "print('tweet 2:\\n', X[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficient matrix vector product:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ z = X * \\beta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X * beta for tweet 1= 6.0\n",
      "which is the same as the sum 6.0, since beta=[1...1]\n"
     ]
    }
   ],
   "source": [
    "# Compute z = X * \\beta, where X is a CSR matrix.\n",
    "import numpy as np\n",
    "beta = np.ones(len(vocabulary))  # assume Beta = vector of 1s\n",
    "z = np.zeros(len(tweets))\n",
    "for i in range(len(tweets)):  # for each row.\n",
    "    for j in range(X.indptr[i], X.indptr[i+1]): # for each col.\n",
    "        colidx = X.indices[j]\n",
    "        z[i] += beta[colidx] * X.data[j]\n",
    "print('X * beta for tweet 1=', z[1])\n",
    "print('which is the same as the sum %.1f, since beta=[1...1]' %\n",
    "      X[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.) Create a list of gender labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender labels: Counter({0: 2955, 1: 2045})\n"
     ]
    }
   ],
   "source": [
    "# y is a 1d numpy array of gender labels.\n",
    "# Let 1=Female, 0=Male.\n",
    "import numpy as np\n",
    "\n",
    "def get_gender(tweet, male_names, female_names):\n",
    "    name = get_first_name(tweet)\n",
    "    if name in female_names:\n",
    "        return 1\n",
    "    elif name in male_names:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "y = np.array([get_gender(t, male_names, female_names) for t in tweets])\n",
    "print('gender labels:', Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.) Fit a Logistic Regression classifier to predict gender from profile/tweet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do 5-fold cross-validation\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def do_cross_val(X, y, nfolds):\n",
    "    \"\"\" Compute average cross-validation acccuracy.\"\"\"\n",
    "    cv = KFold(n_splits=nfolds, random_state=42, shuffle=True)\n",
    "    accuracies = []\n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "    avg = np.mean(accuracies)\n",
    "    print(np.std(accuracies))\n",
    "    print(accuracies)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016740370366273277\n",
      "[0.701, 0.702, 0.732, 0.732, 0.741]\n",
      "avg accuracy 0.7216\n"
     ]
    }
   ],
   "source": [
    "print('avg accuracy', do_cross_val(X, y, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fitting model with CSR much, much faster than with LIL.\n",
    "from timeit import timeit\n",
    "print('CSR TIME')\n",
    "timeit(\"do_cross_val(X.tocsr(), y, 2)\", number=5,\n",
    "       setup=\"from __main__ import do_cross_val, X, y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "print('LIL TIME')\n",
    "timeit(\"do_cross_val(X.tolil(), y, 2)\", number=5,\n",
    "       setup=\"from __main__ import do_cross_val, X, y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See more about vectorization of arithmetic operations: \n",
    "https://en.wikipedia.org/wiki/Automatic_vectorization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does tokenization affect accuracy?\n",
    "# Collapse urls and mentions; ignore description prefix.\n",
    "def run_all(tweets, use_descr=True, lowercase=True,\n",
    "            keep_punctuation=True, descr_prefix=None,\n",
    "            collapse_urls=True, collapse_mentions=True):\n",
    "    \n",
    "    tokens_list = [tweet2tokens(t, use_descr, lowercase,\n",
    "                            keep_punctuation, descr_prefix,\n",
    "                            collapse_urls, collapse_mentions)\n",
    "                  for t in tweets]\n",
    "    vocabulary = make_vocabulary(tokens_list)\n",
    "    X = make_feature_matrix(tokens_list, vocabulary)\n",
    "    acc = do_cross_val(X, y, 5)\n",
    "    print('acc=', acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "30255 unique terms in vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015001333274079355\n",
      "[0.703, 0.716, 0.736, 0.732, 0.745]\n",
      "acc= 0.7264000000000002\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "34878 unique terms in vocabulary\n",
      "0.01400571312000929\n",
      "[0.705, 0.723, 0.736, 0.737, 0.745]\n",
      "acc= 0.7292\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "32357 unique terms in vocabulary\n",
      "0.017197674261364544\n",
      "[0.702, 0.698, 0.733, 0.732, 0.739]\n",
      "acc= 0.7208\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "36980 unique terms in vocabulary\n",
      "0.016740370366273277\n",
      "[0.701, 0.702, 0.732, 0.732, 0.741]\n",
      "acc= 0.7216\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "26569 unique terms in vocabulary\n",
      "0.006164414002968982\n",
      "[0.711, 0.719, 0.73, 0.718, 0.722]\n",
      "acc= 0.72\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "31143 unique terms in vocabulary\n",
      "0.007127411872482192\n",
      "[0.711, 0.72, 0.731, 0.729, 0.724]\n",
      "acc= 0.7230000000000001\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "28672 unique terms in vocabulary\n",
      "0.010438390680559921\n",
      "[0.704, 0.718, 0.728, 0.727, 0.734]\n",
      "acc= 0.7222\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "33246 unique terms in vocabulary\n",
      "0.007138627319029905\n",
      "[0.711, 0.72, 0.725, 0.733, 0.722]\n",
      "acc= 0.7222000000000001\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "20814 unique terms in vocabulary\n",
      "0.005878775382679633\n",
      "[0.727, 0.738, 0.732, 0.742, 0.742]\n",
      "acc= 0.7362\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "25306 unique terms in vocabulary\n",
      "0.00918694726228469\n",
      "[0.726, 0.737, 0.741, 0.75, 0.751]\n",
      "acc= 0.741\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "22946 unique terms in vocabulary\n",
      "0.009604165762834384\n",
      "[0.719, 0.736, 0.733, 0.744, 0.746]\n",
      "acc= 0.7356\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "27433 unique terms in vocabulary\n",
      "0.008546344247688607\n",
      "[0.724, 0.735, 0.743, 0.742, 0.749]\n",
      "acc= 0.7386\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "17103 unique terms in vocabulary\n",
      "0.007858753081755408\n",
      "[0.72, 0.733, 0.734, 0.714, 0.73]\n",
      "acc= 0.7262\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "21487 unique terms in vocabulary\n",
      "0.008039900496896719\n",
      "[0.718, 0.739, 0.734, 0.72, 0.726]\n",
      "acc= 0.7273999999999999\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "19221 unique terms in vocabulary\n",
      "0.007678541528180994\n",
      "[0.723, 0.737, 0.736, 0.717, 0.726]\n",
      "acc= 0.7278\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "23600 unique terms in vocabulary\n",
      "0.0095372952140531\n",
      "[0.717, 0.738, 0.742, 0.723, 0.724]\n",
      "acc= 0.7288\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "34348 unique terms in vocabulary\n",
      "0.01606735821471596\n",
      "[0.699, 0.709, 0.73, 0.718, 0.745]\n",
      "acc= 0.7202\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "38995 unique terms in vocabulary\n",
      "0.0153179633110933\n",
      "[0.702, 0.713, 0.726, 0.714, 0.747]\n",
      "acc= 0.7203999999999999\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "36450 unique terms in vocabulary\n",
      "0.015302287410710873\n",
      "[0.693, 0.708, 0.729, 0.713, 0.736]\n",
      "acc= 0.7158\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "41097 unique terms in vocabulary\n",
      "0.01456021977856105\n",
      "[0.694, 0.707, 0.72, 0.716, 0.738]\n",
      "acc= 0.715\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "30546 unique terms in vocabulary\n",
      "0.008953211714239764\n",
      "[0.712, 0.724, 0.736, 0.717, 0.732]\n",
      "acc= 0.7242\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "35155 unique terms in vocabulary\n",
      "0.007310266752998833\n",
      "[0.714, 0.728, 0.733, 0.72, 0.732]\n",
      "acc= 0.7253999999999999\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "32649 unique terms in vocabulary\n",
      "0.008876936408468867\n",
      "[0.709, 0.727, 0.734, 0.717, 0.728]\n",
      "acc= 0.7230000000000001\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "37258 unique terms in vocabulary\n",
      "0.006968500556073744\n",
      "[0.712, 0.72, 0.731, 0.719, 0.729]\n",
      "acc= 0.7222\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "25250 unique terms in vocabulary\n",
      "0.014853955702101726\n",
      "[0.722, 0.726, 0.732, 0.739, 0.764]\n",
      "acc= 0.7365999999999999\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "29832 unique terms in vocabulary\n",
      "0.01258570617804183\n",
      "[0.725, 0.725, 0.739, 0.751, 0.755]\n",
      "acc= 0.739\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "27413 unique terms in vocabulary\n",
      "0.014759403781996087\n",
      "[0.721, 0.721, 0.737, 0.744, 0.76]\n",
      "acc= 0.7365999999999999\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "31987 unique terms in vocabulary\n",
      "0.01202331069215132\n",
      "[0.725, 0.726, 0.734, 0.753, 0.751]\n",
      "acc= 0.7378\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "21248 unique terms in vocabulary\n",
      "0.004079215610874232\n",
      "[0.722, 0.727, 0.734, 0.726, 0.724]\n",
      "acc= 0.7266\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "25739 unique terms in vocabulary\n",
      "0.007472616676907767\n",
      "[0.723, 0.727, 0.744, 0.729, 0.725]\n",
      "acc= 0.7296\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "23396 unique terms in vocabulary\n",
      "0.0054037024344425226\n",
      "[0.725, 0.727, 0.738, 0.728, 0.722]\n",
      "acc= 0.728\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "27879 unique terms in vocabulary\n",
      "0.008731551981177237\n",
      "[0.721, 0.726, 0.744, 0.735, 0.722]\n",
      "acc= 0.7295999999999999\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "13968 unique terms in vocabulary\n",
      "0.009465727652959395\n",
      "[0.583, 0.611, 0.588, 0.595, 0.593]\n",
      "acc= 0.594\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "17329 unique terms in vocabulary\n",
      "0.008876936408468867\n",
      "[0.593, 0.617, 0.606, 0.613, 0.616]\n",
      "acc= 0.609\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "15894 unique terms in vocabulary\n",
      "0.008588364221433564\n",
      "[0.582, 0.609, 0.595, 0.593, 0.595]\n",
      "acc= 0.5947999999999999\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "19255 unique terms in vocabulary\n",
      "0.007833262411026462\n",
      "[0.596, 0.617, 0.597, 0.608, 0.608]\n",
      "acc= 0.6052000000000001\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "13968 unique terms in vocabulary\n",
      "0.009465727652959395\n",
      "[0.583, 0.611, 0.588, 0.595, 0.593]\n",
      "acc= 0.594\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "17329 unique terms in vocabulary\n",
      "0.008876936408468867\n",
      "[0.593, 0.617, 0.606, 0.613, 0.616]\n",
      "acc= 0.609\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "15894 unique terms in vocabulary\n",
      "0.008588364221433564\n",
      "[0.582, 0.609, 0.595, 0.593, 0.595]\n",
      "acc= 0.5947999999999999\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "19255 unique terms in vocabulary\n",
      "0.007833262411026462\n",
      "[0.596, 0.617, 0.597, 0.608, 0.608]\n",
      "acc= 0.6052000000000001\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "9871 unique terms in vocabulary\n",
      "0.019975985582694054\n",
      "[0.572, 0.606, 0.566, 0.59, 0.619]\n",
      "acc= 0.5905999999999999\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "13159 unique terms in vocabulary\n",
      "0.01705754964817633\n",
      "[0.586, 0.624, 0.583, 0.605, 0.621]\n",
      "acc= 0.6037999999999999\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "11798 unique terms in vocabulary\n",
      "0.022059918404200882\n",
      "[0.571, 0.615, 0.568, 0.592, 0.622]\n",
      "acc= 0.5936\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "15086 unique terms in vocabulary\n",
      "0.017281203661782374\n",
      "[0.585, 0.625, 0.586, 0.608, 0.623]\n",
      "acc= 0.6054\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "9871 unique terms in vocabulary\n",
      "0.019975985582694054\n",
      "[0.572, 0.606, 0.566, 0.59, 0.619]\n",
      "acc= 0.5905999999999999\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "13159 unique terms in vocabulary\n",
      "0.01705754964817633\n",
      "[0.586, 0.624, 0.583, 0.605, 0.621]\n",
      "acc= 0.6037999999999999\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "11798 unique terms in vocabulary\n",
      "0.022059918404200882\n",
      "[0.571, 0.615, 0.568, 0.592, 0.622]\n",
      "acc= 0.5936\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "15086 unique terms in vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017281203661782374\n",
      "[0.585, 0.625, 0.586, 0.608, 0.623]\n",
      "acc= 0.6054\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "15773 unique terms in vocabulary\n",
      "0.014606847709208184\n",
      "[0.579, 0.594, 0.607, 0.58, 0.616]\n",
      "acc= 0.5952\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "19141 unique terms in vocabulary\n",
      "0.012073110618229266\n",
      "[0.592, 0.612, 0.612, 0.604, 0.629]\n",
      "acc= 0.6098\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "17699 unique terms in vocabulary\n",
      "0.01372005830891401\n",
      "[0.573, 0.587, 0.606, 0.58, 0.607]\n",
      "acc= 0.5906\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "21067 unique terms in vocabulary\n",
      "0.017440183485273326\n",
      "[0.581, 0.604, 0.621, 0.599, 0.631]\n",
      "acc= 0.6072000000000001\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "15773 unique terms in vocabulary\n",
      "0.014606847709208184\n",
      "[0.579, 0.594, 0.607, 0.58, 0.616]\n",
      "acc= 0.5952\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "19141 unique terms in vocabulary\n",
      "0.012073110618229266\n",
      "[0.592, 0.612, 0.612, 0.604, 0.629]\n",
      "acc= 0.6098\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "17699 unique terms in vocabulary\n",
      "0.01372005830891401\n",
      "[0.573, 0.587, 0.606, 0.58, 0.607]\n",
      "acc= 0.5906\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "21067 unique terms in vocabulary\n",
      "0.017440183485273326\n",
      "[0.581, 0.604, 0.621, 0.599, 0.631]\n",
      "acc= 0.6072000000000001\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "11830 unique terms in vocabulary\n",
      "0.019528440797974646\n",
      "[0.568, 0.61, 0.594, 0.595, 0.627]\n",
      "acc= 0.5988\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "15148 unique terms in vocabulary\n",
      "0.013047605144240084\n",
      "[0.589, 0.612, 0.618, 0.622, 0.626]\n",
      "acc= 0.6134\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "13757 unique terms in vocabulary\n",
      "0.016977632343763382\n",
      "[0.57, 0.609, 0.598, 0.604, 0.621]\n",
      "acc= 0.6003999999999999\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "17075 unique terms in vocabulary\n",
      "0.012796874618437124\n",
      "[0.589, 0.617, 0.621, 0.62, 0.624]\n",
      "acc= 0.6142000000000001\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "11830 unique terms in vocabulary\n",
      "0.019528440797974646\n",
      "[0.568, 0.61, 0.594, 0.595, 0.627]\n",
      "acc= 0.5988\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "15148 unique terms in vocabulary\n",
      "0.013047605144240084\n",
      "[0.589, 0.612, 0.618, 0.622, 0.626]\n",
      "acc= 0.6134\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "13757 unique terms in vocabulary\n",
      "0.016977632343763382\n",
      "[0.57, 0.609, 0.598, 0.604, 0.621]\n",
      "acc= 0.6003999999999999\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "17075 unique terms in vocabulary\n",
      "0.012796874618437124\n",
      "[0.589, 0.617, 0.621, 0.62, 0.624]\n",
      "acc= 0.6142000000000001\n"
     ]
    }
   ],
   "source": [
    "argnames = ['use_descr', 'lower', 'punct', 'prefix', 'url', 'mention']\n",
    "option_iter = product(use_descr_opts, lowercase_opts,\n",
    "                       keep_punctuation_opts,\n",
    "                       descr_prefix_opts, url_opts,\n",
    "                       mention_opts)\n",
    "results = []\n",
    "for options in option_iter:\n",
    "    option_str = '\\t'.join('%s=%s' % (name, opt) for name, opt\n",
    "                           in zip(argnames, options))\n",
    "    print(option_str)\n",
    "    acc = run_all(tweets, *options)\n",
    "    results.append((acc, options))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7410 use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "0.7390 use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "0.7386 use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "0.7378 use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "0.7366 use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "0.7366 use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "0.7362 use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "0.7356 use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "0.7296 use_descr=True  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "0.7296 use_descr=True  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "0.7292 use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "0.7288 use_descr=True  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "0.7280 use_descr=True  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "0.7278 use_descr=True  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "0.7274 use_descr=True  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "0.7266 use_descr=True  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "0.7264 use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "0.7262 use_descr=True  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "0.7254 use_descr=True  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "0.7242 use_descr=True  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "0.7230 use_descr=True  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "0.7230 use_descr=True  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "0.7222 use_descr=True  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "0.7222 use_descr=True  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "0.7222 use_descr=True  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "0.7216 use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "0.7208 use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "0.7204 use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "0.7202 use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "0.7200 use_descr=True  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "0.7158 use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "0.7150 use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "0.6142 use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "0.6142 use_descr=False  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "0.6134 use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "0.6134 use_descr=False  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "0.6098 use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "0.6098 use_descr=False  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "0.6090 use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "0.6090 use_descr=False  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "0.6072 use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "0.6072 use_descr=False  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "0.6054 use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "0.6054 use_descr=False  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "0.6052 use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "0.6052 use_descr=False  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "0.6038 use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "0.6038 use_descr=False  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "0.6004 use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "0.6004 use_descr=False  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "0.5988 use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "0.5988 use_descr=False  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "0.5952 use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "0.5952 use_descr=False  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "0.5948 use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "0.5948 use_descr=False  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "0.5940 use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "0.5940 use_descr=False  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "0.5936 use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "0.5936 use_descr=False  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "0.5906 use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "0.5906 use_descr=False  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "0.5906 use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "0.5906 use_descr=False  lower=True  punct=False  prefix=  url=True  mention=True\n"
     ]
    }
   ],
   "source": [
    "for r in sorted(results, reverse=True):\n",
    "    print('%.4f' % r[0], '  '.join('%s=%s' % (name, opt) for name, opt in zip(argnames, r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = dict((v,k) for k,v in vocabulary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for female class:\n",
      "('d=mom', 2.1853148269746137)\n",
      "('d=mom,', 1.9838019256913704)\n",
      "('d=mother', 1.952389697968522)\n",
      "('d=she/her', 1.8255490410673345)\n",
      "('d=mom.', 1.466965688864565)\n",
      "('d=lover', 1.2140666799352833)\n",
      "('d=mother,', 1.162578471283422)\n",
      "('d=girl', 1.1049602444079802)\n",
      "('d=wife,', 1.0179491390029631)\n",
      "('d=give', 1.0090032455316127)\n",
      "('d=dog', 0.9772351641462694)\n",
      "('d=💕', 0.9594829734653065)\n",
      "('doing', 0.9592173445033286)\n",
      "('@gtconway3d', 0.9526179289780334)\n",
      "('d=🖤', 0.9032747855846381)\n",
      "('d=she/her.', 0.9017975162193037)\n",
      "('d=teacher', 0.8994969179342305)\n",
      "('d=know', 0.8946639186709381)\n",
      "('d=bitch', 0.8924329199146204)\n",
      "('🥴', 0.8886474269126446)\n",
      "\n",
      "top weighted terms for male class:\n",
      "('d=father', -1.7541046400630138)\n",
      "('d=husband', -1.3771536404264015)\n",
      "('d=dad', -1.30456924200691)\n",
      "('d=guy', -1.3001675736374787)\n",
      "('d=get', -1.1971790986757493)\n",
      "('d=he/him', -1.1971736849834944)\n",
      "('d=husband,', -1.114734749501193)\n",
      "('d=st.', -1.0902708356050672)\n",
      "('d=free', -1.0529792230555193)\n",
      "('d=wrestling', -0.9828773351863563)\n",
      "('d=he/him.', -0.9742908568086689)\n",
      "('times', -0.9546989690768317)\n",
      "('d=snapchat:', -0.9167272956583409)\n",
      "('d=dad,', -0.8671519048145644)\n",
      "('d=producer', -0.8647174810300932)\n",
      "('d=go', -0.8607732242259684)\n",
      "('d=father,', -0.8538471995372785)\n",
      "('d=opinions', -0.8479359457620205)\n",
      "('d=hardcore', -0.8380324134716626)\n",
      "('d=his', -0.8349244917210948)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit model on all data and print top coef.\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "# Get the learned coefficients for the Positive class.\n",
    "coef = model.coef_[0]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1][:20]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = [idx2word[i] for i in top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print('top weighted terms for female class:')\n",
    "print('\\n'.join(str(x) for x in zip(top_coef_terms, top_coef)))\n",
    "\n",
    "# repeat for males\n",
    "top_coef_ind = np.argsort(coef)[:20]\n",
    "top_coef_terms = [idx2word[i] for i in top_coef_ind]\n",
    "top_coef = coef[top_coef_ind]\n",
    "print('\\ntop weighted terms for male class:')\n",
    "print('\\n'.join(str(x) for x in zip(top_coef_terms, top_coef)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHNxJREFUeJzt3XtwXGeZ5/HvI/VFV1uSJd/t2GZNEodLCCJAwbBkIEMSLpnhGrYKGJZZb83AXHZ3tjbADsPOzlbBbO3MLEWKjIEsyTDFnYBnMWQCZMlkICQKOIkdJ7FiO7Hlmy7WtdVXPfvHOXbajqS21UetVvfvU9XV56bzPjpqvc857/v2OebuiIhI/WlY6gBERGRpKAGIiNQpJQARkTqlBCAiUqeUAERE6pQSgIhInVICEBGpU0oAIiJ1SglARKROxZY6gPl0d3f7li1bljoMEZFl45FHHhly956L2baqE8CWLVvo6+tb6jBERJYNM3v2YrdVE5CISJ1SAhARqVNKACIidUoJQESkTikBiIjUKSUAEZE6pQQgIlKnlABERKrIvU+c4vafPVORspQARESqyE+fPM2XHzhckbKUAERE6pQSgIhIVfGKlaQEICJSZaxC5SgBiIjUKSUAEZE6VXYCMLNNZnafmT1hZvvN7I9n2cbM7HNm1m9mj5nZNeWWKyJSi7xyXQCRPA8gD/wnd/+VmbUDj5jZve7+RNE2NwLbw9ergS+E7yIicgGrUCdA2VcA7n7C3X8VTk8AB4ANF2x2M3CXBx4EOsxsXblli4jIwkXaB2BmW4BXAL+8YNUG4GjR/DFemCREROpeJZuAIksAZtYGfAf4E3cfL2M/O82sz8z6BgcHowpPRGTZsAoNBI0kAZhZnKDy/wd3/+4smwwAm4rmN4bLXsDdd7l7r7v39vRc1HONRURkAaIYBWTAl4ED7v7Xc2y2G/hgOBroNcCYu58ot2wREVm4KEYBvQ74APC4me0Nl30C2Azg7rcDe4CbgH4gBXw4gnJFRGqOV/BWEGUnAHd/gBLfXHZ3Bz5ablkiIvVg2QwDFRGR5UkJQESkiizLYaAiIhIN3Q1UREQWlRKAiEidUgIQEakiFewCUAIQEak2VqFxoEoAIiJ1SglARKSKaBioiIgsOiUAEZE6pQQgIlKnlABERKpIJe8GqgQgIlJldDdQERFZVEoAIiLVZLkNAzWzO8zstJntm2P9G81szMz2hq9PRVGuiEgtqlQTUBSPhAT4CvB54K55tvlnd39bROWJiEiZIrkCcPf7gZEo9iUiIpVRyT6A15rZo2b2QzO7qoLliogsG5W8G2hUTUCl/Aq4zN0nzewm4HvA9tk2NLOdwE6AzZs3Vyg8EZHqYRV6JlhFrgDcfdzdJ8PpPUDczLrn2HaXu/e6e29PT08lwhMRqUsVSQBmttbCG1yb2bVhucOVKFtEZDnxCt4ONJImIDP7GvBGoNvMjgF/DsQB3P124N3A75tZHpgGbvFK/pYiIsvIshoG6u7vL7H+8wTDREVEpErom8AiInVKCUBEpIroofAiInWsQl0ASgAiIvVKCUBEpIroofAiInXMKjQOVAlARKROKQGIiNQpJQARkSqiYaAiInVMw0BFRGRRKQGIiFSRSt4nUwlARKTaVKgNSAlARKROKQGIiNQpJQARkSqy7IaBmtkdZnbazPbNsd7M7HNm1m9mj5nZNVGUKyJSi5bbMNCvADfMs/5GYHv42gl8IaJyRURkgSJJAO5+PzAyzyY3A3d54EGgw8zWRVG2iEhNqcG7gW4AjhbNHwuXiYhIkfzMDLGGylTNVdcJbGY7zazPzPoGBweXOhwRkYrKF5x4rLZuBz0AbCqa3xguewF33+Xuve7e29PTU5HgRESqRbZQe1cAu4EPhqOBXgOMufuJCpUtIrJs5AozJBorUzXHotiJmX0NeCPQbWbHgD8H4gDufjuwB7gJ6AdSwIejKFdEpNbkC04yvowSgLu/v8R6Bz4aRVkiIrUsV5ihNRlJ1VxS1XUCi4jUs2zBiVeoCUgJQESkiuQLMyRqbBSQiIhchFwNjgISEZGLkFMTkIhIfcoVZog3qglIRKTuBAlAVwAiInXF3ZnM5GlJNlakPCUAEZEqMZHJkys43a3JipSnBCAiUiWGJ7MArGpLVKQ8JQARkSoxMpUBoKtVCUBEpK4MhVcA3W1qAhIRqStqAhIRqVNqAhIRqVNDk1nakzGSMQ0DFRGpKyNT2Yo1/4ASgIhI1Tg1nq5YBzBElADM7AYze8rM+s3s1lnW/66ZDZrZ3vD1e1GUKyJSS54dTrG5q6Vi5ZX92BkzawRuA64HjgEPm9lud3/igk2/4e4fK7c8EZFaNDSZ4eR4mh3rV1SszCiuAK4F+t39kLtnga8DN0ewXxGRurH/+DgAV61fWbEyo0gAG4CjRfPHwmUXepeZPWZm3zazTRGUKyJSMx4/Ngqw7K4ALsY/Alvc/WXAvcCdc21oZjvNrM/M+gYHBysUnojI0vrZ04O8qKeVlc3xipUZRQIYAIrP6DeGy85x92F3z4SzXwJeOdfO3H2Xu/e6e29PT08E4YmIVLfJTJ5Hj41x3eWrK1puFAngYWC7mW01swRwC7C7eAMzW1c0+w7gQATliojUhK/8y2Gy+Rne+rJ1pTeOUNmjgNw9b2YfA+4BGoE73H2/mf0F0Ofuu4E/MrN3AHlgBPjdcssVEakFE+kcX3rgMG+6YjWv2NxZ0bLLTgAA7r4H2HPBsk8VTX8c+HgUZYmI1JK//L8HGE3l+MM3ba942fomsIjIEnng4BDf6DvKzjds4+pNHRUvXwlARGQJ7BsY4w+/9ite1NPKf7z+xUsSQyRNQCIicnGmswU++6MnufMXR+huS/LFD/bSFK/M3T8vpAQgIlIhh4em+KOv/Zp9x8d47ys3ceuNV9BZoXv/z0YJQERkkR08NcFt9/Xzvb3HaUk08sUP9PLmHWuWOiwlABGRxTCVyfPdXw/wrb6jPHZsjFiD8e/fsI2PvH4rq1c0LXV4gBKAiEhkMvkCfUfO8KN9J/ne3gEm0nmuWNvOf33rldx89QZ62it3r/+LoQQgIrJAMzPOkycn6Ht2hL4jZ7j/4CCjqRzJWAPX71jDh1+3lWs2d2BmSx3qrJQARERKKMw4x0en6R+c5OCpCQ4PTfHUyQmePjXJZCYPwOr2JNddvpobXrKW39jeTUui+qvX6o9QRKRChiczHD0zTf/pSQ6enmBwPMOhoSmePjVBKls4t11nS5ztq9t55zUbuHpTB6/a0sXGzuaqPdOfixKAiNSNmRlnYHSaZ4dTnBpPc2R4isNDUzw7nGJgdJqRqey5bRONDfS0J9nc1cJ7ezdxxdp2tvW0sX1125IO3YySEoCI1IxsfoZT42meHU5xYiyo6IensgxOpDk0NMWxkWmyhZlz2zcYbOxs4bJVLbxkw0q2dbeypbuVrd2tbFnVQqyxtm+WoAQgIlWrMONMZvIMTqQ5MpTi5HiaM1NZRqdzjExlOZPKMprKMZrKciaVY2w6d97PNzYYnS1xutuSvHh1O9fvWMNlXa1s62lldXuSjZ0tJGK1XcnPRwlARBZdOldgNJVjMpNjIp1nbDp4n8zkmUznGU8HFfrpiQyjqSzj03mOj00zkc7Pur+WRCOdLQm6WhN0tMTZ1NVCR3OcnvYka1Yk2dTVwvqVzWzobCZe42fx5VACEJFLks4VODmWZiSVDc7GwzPv8XSO8ek8w1OZc2fnw5NZRqayZPIz8+6zwWBlc5zV7U10tSbY2t3Kq7d10dWaoC0Zo7styeZVLWzsaKajJVHXZ+1RUgIQqWPuQRPL0GQ2PCvPcSaVY3gyw9BkhtPjGc6kcoxP5xiczHByLM10rjDn/loTjaxqS9LVmqCnLcnla1awqi3ByuY4nS0J2ppitCUb6WgJKva2ZIz2phitiRgNDctrBE0tiCQBmNkNwP8meCLYl9z9MxesTwJ3ETwLeBh4n7sfiaJsEXmhbH6G0VSWY6PTnBpLMzSVZXAiw/BkhsGJDKcngvfhqQzp3Oxn540NRk9bko6WOCub4+xYv4LrLl/NqrYEa1Y00dUaVOqdLUEzTFsyVvOdprWm7ARgZo3AbcD1wDHgYTPb7e5PFG32EeCMu/8rM7sF+CzwvnLLFqlX7s6JsTTPjaR4ZnCS46PTnBzL8NzIFIeHUgxNZl7wM2bQETaz9LQn2dbdyqq2BD3tSbrDir4tGaerNc6q1iQrm+M6K69xUVwBXAv0u/shADP7OnAzUJwAbgY+HU5/G/i8mZm7ewTli9S80xNp+o6c4aHDIzx5cpyDpyYZLhqzfvZsfXNXC9dd3sPGzha6WuOs72hm7comesJmGZ2hS7EoEsAG4GjR/DHg1XNtEz5EfgxYBQxFUL7IslWYcUZTWYangg7VkamgLX5sOsfQZIZDg1M8fXqCoyPTQDD65cVr2vnNK1bzso0r2drdxpbuYMSLztblUlVdJ7CZ7QR2AmzevHmJoxGZXa4wQypbYDpbIJXNk8oWSGULTGWCoY1TmTxT2QKpTDDEcSIc6jg+HbxPhkMhR6dzFGZmvxBONDawraeVl23o4IOv2cIrt3Ty0g0rNaxRIhNFAhgANhXNbwyXzbbNMTOLASsJOoNfwN13AbsAent71UQkCzYz46TzBaYyBdK5QlhJ58NKu0A6XyCVKTARjkVP5YJ1z28fVOzTuaBiP1vJp7J5coWL/2g2xRtob4qzoinGinA0zOaulnA6HjTPtCXpCse1r2yJ09EcpyXRuOzuLSPLSxQJ4GFgu5ltJajobwH+zQXb7AY+BPwCeDfwU7X/16+zFXM6N0M6VyCTD96nc0HFmwmXT6TzTGXz51XA6dwMmaJt07kZ0vngTPzsfs4un2+44mwSsQZaEo20JmI0JxppjgevrtYEGzubaU3EaEk00hy+B9ON4XSw7OzQxramGC3xGC3JRp2xS9UqOwGEbfofA+4hGAZ6h7vvN7O/APrcfTfwZeDvzawfGCFIElLl8oUZUrngLHkqmyeVef6s+Oz81Nn5zAXvF6xPhfOZ/Mx592K5WA0GrYkYyXgjTfEGmsLKuSneQFsyxqrW5AuWN8eDyrotGbw3x5+vtIN1jbQmY7QlYrQmG9VBKnUnkj4Ad98D7Llg2aeKptPAe6IoS+aXzc8wkQ46Ec9+E3MinWcinQvaprMFsvmg/Xo8nQsq7LCiLj5znsrkS357s1hjg9EaVqgtRe9rVzTRkozRmmikKX72FVTUTbGG85Ylz1XejSRjQcV+dj/JWIOaQ0QiVnWdwPUum5/hTOr5m1wVV95jqaDTcDy8j8pEeF+VyXT+XDt2qWaPeKORjAWV7IrmGO3JGC2JGGtXNNGUaKQp9vxZdUt4Znzee6LxXIXeHDaXtCQbSTSqghZZbpQAKiBfmGFgdJqBM9OcnshwJhUM9xuazDIylWFoMsvQZHD/lLlufnVWS6KRlc1xVjTFaWuK0dWaYFNXCyuagrbnlc3BNzI7wm9nrmpN0h52PrYlY7qHioicowQQkbFUjkNDkxwemuLoyDRHz6R4biTF6fE0A6PTLxg10mCcu5thT3uSl2/soKs1cd6rozlOe1Oc9qagU3FFU1wVuIhERgngEpx9mtCTJyc4cGKcZ4dTHB6a5Mhw6rwnCUHwfNCzD5m44SXr2NbdysauZtasaArunaKv2YvIElMCmMfIVJYHDw3zL/1D7D8+/oLngq5ZkWRrdytvuWotW7tb2NrdxtbuVjZ2NtMUb1zCyEVESlMCKDIz4/z66Cg/eOwEP39miCdPTgDQnoxx5boVvO9Vm7h8TTvb17Rz5bp2WhI6fCKyfKkGA/YfH+Pbjxzjh4+f5OR4mmSsgVdt6eI/v2U9r33RKn39XkRqUt0mAHfnnv0nufPnz/KLQ8PEG43rLl/Nn151Ob911RpWNMWXOkQRkUVVlwngwIlxPnH34/z6uVHWr2zi4zdewXt7N9HZmljq0EREKqbuEsBt9/Xz1/c+TUdznM++66W865qNugWAiNSlukkAhRnnz3fv46sPPsfbX76eT799B6vakksdlojIkqmbBPDZHz3JVx98jo+8fiufuOlKGjUGX0TqXF0kgO88coxd9x/iA6+5jD97246lDkdEpCrUfOP3eDrHf//BE1y7pYtPvV2Vv4jIWTWfAP7uZ88wmsrxZ2/bobH8IiJFarpGHEvl+PIDh3nHy9fz0o0rlzocEZGqUlYCMLMuM7vXzA6G751zbFcws73ha3c5ZV6Kf3zsOOncDP/uN7ZVqkgRkWWj3CuAW4GfuPt24Cfh/Gym3f3q8PWOMsu8aD85cIqt3a06+xcRmUW5CeBm4M5w+k7gt8vcX2TSuQK/ODTMv35xz1KHIiJSlcpNAGvc/UQ4fRJYM8d2TWbWZ2YPmllFksTDR0ZI52aUAERE5lDyewBm9mNg7SyrPlk84+5uZj7LdgCXufuAmW0Dfmpmj7v7M3OUtxPYCbB58+ZS4c3p588ME2swXr2ta8H7EBGpZSUTgLu/ea51ZnbKzNa5+wkzWwecnmMfA+H7ITP7f8ArgFkTgLvvAnYB9Pb2zpVQSnrw0DAv39She/aLiMyh3Cag3cCHwukPAd+/cAMz6zSzZDjdDbwOeKLMckt6bjjFi9e0L3YxIiLLVrkJ4DPA9WZ2EHhzOI+Z9ZrZl8JtrgT6zOxR4D7gM+6+qAkglc0zPJVlY2fzYhYjIrKsldU+4u7DwJtmWd4H/F44/XPgpeWUc6mOj04DKAGIiMyjJr8JfOxMkAA2dCgBiIjMpSYTwEB4BbBBVwAiInOqyQRwZioLwKpWPfBFRGQuNZkA0rkZGgzijXroi4jIXGoyAWTyBZrijZgpAYiIzKUmE0A6N0MyVpO/mohIZGqyljx7BSAiInOryQSgKwARkdJqspZM53QFICJSSk0mgExeVwAiIqXUZC2ZzhVI6gpARGReNZkAMvkZNQGJiJRQkwkgnSuoCUhEpISarCXzM65vAYuIlFCTCcDdMZQARETmU5sJAFD9LyIyv7ISgJm9x8z2m9mMmfXOs90NZvaUmfWb2a3llHnRsVWiEBGRZazcK4B9wDuB++fawMwagduAG4EdwPvNbEeZ5c5vwY+SFxGpH+U+EvIAUOqum9cC/e5+KNz268DNLOKD4b10TCIida8SfQAbgKNF88fCZYtK1b+IyPxKXgGY2Y+BtbOs+qS7fz/qgMxsJ7ATYPPmzQvah7vagERESimZANz9zWWWMQBsKprfGC6bq7xdwC6A3t7eBdXkQRPQQn5SRKR+VKIJ6GFgu5ltNbMEcAuwe7ELVf0vIjK/coeB/o6ZHQNeC/zAzO4Jl683sz0A7p4HPgbcAxwAvunu+8sLe35qARIRKa3cUUB3A3fPsvw4cFPR/B5gTzllXVJcuEYBiYiUUJvfBHY1AYmIlFKTCQBQBhARKaEmE4D6AERESqvJBADobqAiIiXUbgJQ/S8iMq+aTAD6JrCISGm1mQBQH7CISCk1mQBATUAiIqXUZAJQC5CISGm1mQDQM4FFREqpzQTgagISESmlJhMAKAGIiJRSkwlAXQAiIqXVZgJw0EBQEZH51WQCADUBiYiUUqMJQI1AIiKl1GQC0PMARERKK/eRkO8xs/1mNmNmvfNsd8TMHjezvWbWV06ZF0MPhRcRKa2sR0IC+4B3An93Edte5+5DZZYnIiIRKfeZwAeAqnv+rru+CSwiUkql+gAc+Ccze8TMds63oZntNLM+M+sbHBxccGFVlpNERKpOySsAM/sxsHaWVZ909+9fZDmvd/cBM1sN3GtmT7r7/bNt6O67gF0Avb29Cx7Oo/pfRGR+JROAu7+53ELcfSB8P21mdwPXArMmgCjobqAiIqUtehOQmbWaWfvZaeC3CDqPF427V12/hIhItSl3GOjvmNkx4LXAD8zsnnD5ejPbE262BnjAzB4FHgJ+4O4/KqdcEREpX7mjgO4G7p5l+XHgpnD6EPDycsq55LgqWZiIyDJVk98ERs8DEBEpqSYTQPBQeGUAEZH51GQCAF0BiIiUUpMJwDUOVESkpNpMAOiLYCIipdRkAgA1AYmIlFKTCUAtQCIipdVkArjhJWu5ct2KpQ5DRKSqlfs8gKr0N++7eqlDEBGpejV5BSAiIqUpAYiI1CklABGROqUEICJSp5QARETqlBKAiEidUgIQEalTSgAiInXKqvnOmWY2CDy7wB/vBoYiDGcxKMZoKMboLIc4FeP8LnP3novZsKoTQDnMrM/de5c6jvkoxmgoxugshzgVY3TUBCQiUqeUAERE6lQtJ4BdSx3ARVCM0VCM0VkOcSrGiNRsH4CIiMyvlq8ARERkHjWXAMzsBjN7ysz6zezWJSj/iJk9bmZ7zawvXNZlZvea2cHwvTNcbmb2uTDWx8zsmqL9fCjc/qCZfSiCuO4ws9Nmtq9oWWRxmdkrw9+7P/zZS34o5xwxftrMBsLjudfMbipa9/GwvKfM7C1Fy2f9DJjZVjP7Zbj8G2aWuMT4NpnZfWb2hJntN7M/rtLjOFec1XQsm8zsITN7NIzxv823XzNLhvP94fotC409ghi/YmaHi47j1eHyJfl7l8Xda+YFNALPANuABPAosKPCMRwBui9Y9lfAreH0rcBnw+mbgB8SPMP+NcAvw+VdwKHwvTOc7iwzrjcA1wD7FiMu4KFwWwt/9saIYvw08KezbLsj/Psmga3h371xvs8A8E3glnD6duD3LzG+dcA14XQ78HQYR7Udx7nirKZjaUBbOB0Hfhn+3rPuF/gD4PZw+hbgGwuNPYIYvwK8e5btl+TvXc6r1q4ArgX63f2Qu2eBrwM3L3FMEMRwZzh9J/DbRcvv8sCDQIeZrQPeAtzr7iPufga4F7ihnADc/X5gZDHiCtetcPcHPfhU31W0r3JjnMvNwNfdPePuh4F+gr//rJ+B8MzqN4Fvz/L7Xmx8J9z9V+H0BHAA2ED1Hce54pzLUhxLd/fJcDYevnye/RYf428DbwrjuKTYI4pxLkvy9y5HrSWADcDRovljzP/BXwwO/JOZPWJmO8Nla9z9RDh9ElgTTs8Vb6V+j6ji2hBOL1a8Hwsvqe8427yygBhXAaPuno8ixrAJ4hUEZ4VVexwviBOq6FiaWaOZ7QVOE1SKz8yz33OxhOvHwjgW9X/owhjd/exx/B/hcfwbM0teGONFxrLY/zcl1VoCqAavd/drgBuBj5rZG4pXhpm+6oZeVWtcwBeAFwFXAyeA/7W04YCZtQHfAf7E3ceL11XTcZwlzqo6lu5ecPergY0EZ+xXLGU8s7kwRjN7CfBxglhfRdCs81+WMMSy1FoCGAA2Fc1vDJdVjLsPhO+ngbsJPtinwss9wvfT4eZzxVup3yOquAbC6cjjdfdT4T/hDPBFguO5kBiHCS7JY+XEaGZxgkr1H9z9u+HiqjuOs8VZbcfyLHcfBe4DXjvPfs/FEq5fGcZRkf+hohhvCJvY3N0zwP9h4cdx0f5vLlrUnQpL+QJiBB0sW3m+4+eqCpbfCrQXTf+coO3+f3J+J+FfhdNv5fxOo4f8+U6jwwQdRp3hdFcE8W3h/A7WyOLihZ1ZN0UU47qi6f9A0N4LcBXnd/4dIuj4m/MzAHyL8zsY/+ASYzOCdtq/vWB5VR3HeeKspmPZA3SE083APwNvm2u/wEc5vxP4mwuNPYIY1xUd578FPrPU/zcLrhMqWVhFfqGgJ/5pgvbET1a47G3hB+1RYP/Z8gnaKn8CHAR+XPTHN+C2MNbHgd6iff1bgg6tfuDDEcT2NYLL/hxBW+NHoowL6AX2hT/zecIvGUYQ49+HMTwG7Ob8SuyTYXlPUTR6Yq7PQPj3eSiM/VtA8hLjez1B885jwN7wdVMVHse54qymY/ky4NdhLPuAT823X6ApnO8P129baOwRxPjT8DjuA77K8yOFluTvXc5L3wQWEalTtdYHICIiF0kJQESkTikBiIjUKSUAEZE6pQQgIlKnlABEROqUEoCISJ1SAhARqVP/H/DzFUxF0dcaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sorted(coef))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21833857880466098"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[vocabulary['dress']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.26050318745822415"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[vocabulary['she']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23311302114587082"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[vocabulary['he']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23952162509047734"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[vocabulary['the']]  # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45500815966643854"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[vocabulary['coffee']]  # ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "- Which ones do we get wrong?\n",
    "- Are there obvious reasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from IPython.core.display import HTML\n",
    "HTML(open('../custom.css').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
